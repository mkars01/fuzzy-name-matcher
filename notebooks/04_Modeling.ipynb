{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6ad0746",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import MaxAbsScaler, MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import tensorflow as tf \n",
    "import random\n",
    "import gc\n",
    "import re\n",
    "import os\n",
    "import unidecode\n",
    "from datetime import datetime\n",
    "from itertools import combinations\n",
    "from fuzzywuzzy import fuzz\n",
    "# from tensorflow.python.platform import gfile\n",
    "# from tensorflow.io import gfile\n",
    "import tensorflow.compat.v1.gfile as gfile\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from abydos.phones import *\n",
    "from abydos.distance import (IterativeSubString, BISIM, DiscountedLevenshtein, Prefix, LCSstr, MLIPNS, Strcmp95,\n",
    "MRA, Editex, SAPS, FlexMetric, JaroWinkler, HigueraMico, Sift4, Eudex, ALINE, Covington, PhoneticEditDistance)\n",
    "from abydos.phonetic import PSHPSoundexFirst, Ainsworth\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except ImportError:\n",
    "    import pickle\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a154250",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b84edf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interim Data File Locations\n",
    "interim_data = '../data/interim/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05000356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87550, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(interim_data + 'feature_engineering_results.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "89b085e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>target</th>\n",
       "      <th>name_a</th>\n",
       "      <th>name_b</th>\n",
       "      <th>partial</th>\n",
       "      <th>tkn_sort</th>\n",
       "      <th>tkn_set</th>\n",
       "      <th>sum_ipa</th>\n",
       "      <th>pshp_soundex_first</th>\n",
       "      <th>...</th>\n",
       "      <th>editex</th>\n",
       "      <th>saps</th>\n",
       "      <th>flexmetric</th>\n",
       "      <th>jaro</th>\n",
       "      <th>higueramico</th>\n",
       "      <th>sift4</th>\n",
       "      <th>eudex</th>\n",
       "      <th>aline</th>\n",
       "      <th>covington</th>\n",
       "      <th>phoneticeditdistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41989</th>\n",
       "      <td>Henrietta</td>\n",
       "      <td>Wilhelm</td>\n",
       "      <td>0</td>\n",
       "      <td>henrietta</td>\n",
       "      <td>wilhelm</td>\n",
       "      <td>53</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>0.540323</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305556</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.109343</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.881863</td>\n",
       "      <td>0.293617</td>\n",
       "      <td>0.411392</td>\n",
       "      <td>0.650538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87094</th>\n",
       "      <td>Abel</td>\n",
       "      <td>Mo</td>\n",
       "      <td>0</td>\n",
       "      <td>abel</td>\n",
       "      <td>mo</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.322581</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.806863</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.459677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86120</th>\n",
       "      <td>Yannig</td>\n",
       "      <td>Olezha</td>\n",
       "      <td>0</td>\n",
       "      <td>yannig</td>\n",
       "      <td>olezha</td>\n",
       "      <td>52</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>0.615591</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.787745</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.653226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9270</th>\n",
       "      <td>Lon</td>\n",
       "      <td>Laurence</td>\n",
       "      <td>1</td>\n",
       "      <td>lon</td>\n",
       "      <td>laurence</td>\n",
       "      <td>57</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.506250</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.969608</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.509804</td>\n",
       "      <td>0.370968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80674</th>\n",
       "      <td>Rafael</td>\n",
       "      <td>Toncio</td>\n",
       "      <td>0</td>\n",
       "      <td>rafael</td>\n",
       "      <td>toncio</td>\n",
       "      <td>57</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>0.670507</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.612255</td>\n",
       "      <td>0.223333</td>\n",
       "      <td>0.515625</td>\n",
       "      <td>0.755376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52317</th>\n",
       "      <td>Varvara</td>\n",
       "      <td>Mareczek</td>\n",
       "      <td>0</td>\n",
       "      <td>varvara</td>\n",
       "      <td>mareczek</td>\n",
       "      <td>63</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>0.722581</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325000</td>\n",
       "      <td>0.511905</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.782353</td>\n",
       "      <td>0.336364</td>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.735887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34605</th>\n",
       "      <td>Helene</td>\n",
       "      <td>Emeline</td>\n",
       "      <td>0</td>\n",
       "      <td>helene</td>\n",
       "      <td>emeline</td>\n",
       "      <td>83</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>0.564516</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.296296</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.782540</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.668627</td>\n",
       "      <td>0.651515</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.815668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46653</th>\n",
       "      <td>Colt</td>\n",
       "      <td>Quique</td>\n",
       "      <td>0</td>\n",
       "      <td>colt</td>\n",
       "      <td>quique</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.717742</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.283333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.807353</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.548387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32978</th>\n",
       "      <td>Stana</td>\n",
       "      <td>Tatsuyakun</td>\n",
       "      <td>0</td>\n",
       "      <td>stana</td>\n",
       "      <td>tatsuyakun</td>\n",
       "      <td>69</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.081638</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.839216</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.464789</td>\n",
       "      <td>0.443548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68038</th>\n",
       "      <td>Nichole</td>\n",
       "      <td>Maxim</td>\n",
       "      <td>0</td>\n",
       "      <td>nichole</td>\n",
       "      <td>maxim</td>\n",
       "      <td>54</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>0.691244</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.185714</td>\n",
       "      <td>0.447619</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.894608</td>\n",
       "      <td>0.278378</td>\n",
       "      <td>0.423729</td>\n",
       "      <td>0.603687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               a           b  target     name_a      name_b  partial  \\\n",
       "41989  Henrietta     Wilhelm       0  henrietta     wilhelm       53   \n",
       "87094       Abel          Mo       0       abel          mo       50   \n",
       "86120     Yannig      Olezha       0     yannig      olezha       52   \n",
       "9270         Lon    Laurence       1        lon    laurence       57   \n",
       "80674     Rafael      Toncio       0     rafael      toncio       57   \n",
       "52317    Varvara    Mareczek       0    varvara    mareczek       63   \n",
       "34605     Helene     Emeline       0     helene     emeline       83   \n",
       "46653       Colt      Quique       0       colt      quique       38   \n",
       "32978      Stana  Tatsuyakun       0      stana  tatsuyakun       69   \n",
       "68038    Nichole       Maxim       0    nichole       maxim       54   \n",
       "\n",
       "       tkn_sort  tkn_set   sum_ipa  pshp_soundex_first  ...    editex  \\\n",
       "41989        42       42  0.540323                   0  ...  0.333333   \n",
       "87094         0        0  0.322581                   0  ...  0.125000   \n",
       "86120        13       13  0.615591                   0  ...  0.166667   \n",
       "9270         31       31  0.967742                   1  ...  0.375000   \n",
       "80674        14       14  0.670507                   0  ...  0.166667   \n",
       "52317        42       42  0.722581                   0  ...  0.312500   \n",
       "34605        78       78  0.564516                   0  ...  0.642857   \n",
       "46653         0        0  0.717742                   0  ...  0.333333   \n",
       "32978        42       42  0.677419                   0  ...  0.300000   \n",
       "68038        27       27  0.691244                   0  ...  0.214286   \n",
       "\n",
       "           saps  flexmetric      jaro  higueramico     sift4     eudex  \\\n",
       "41989  0.000000    0.305556  0.476190     0.109343  0.222222  0.881863   \n",
       "87094  0.000000    0.350000  0.000000     0.000000  0.000000  0.806863   \n",
       "86120  0.000000    0.116667  0.000000     0.000000  0.166667  0.787745   \n",
       "9270   0.000000    0.506250  0.638889     0.000000  0.250000  0.969608   \n",
       "80674  0.000000    0.100000  0.000000     0.000000  0.000000  0.612255   \n",
       "52317  0.000000    0.325000  0.511905     0.250000  0.250000  0.782353   \n",
       "34605  0.296296    0.657143  0.782540     0.571429  0.571429  0.668627   \n",
       "46653  0.000000    0.283333  0.000000     0.000000  0.000000  0.807353   \n",
       "32978  0.000000    0.345000  0.650000     0.081638  0.300000  0.839216   \n",
       "68038  0.000000    0.185714  0.447619     0.000000  0.142857  0.894608   \n",
       "\n",
       "          aline  covington  phoneticeditdistance  \n",
       "41989  0.293617   0.411392              0.650538  \n",
       "87094  0.300000   0.344828              0.459677  \n",
       "86120  0.216667   0.421875              0.653226  \n",
       "9270   0.312500   0.509804              0.370968  \n",
       "80674  0.223333   0.515625              0.755376  \n",
       "52317  0.336364   0.553333              0.735887  \n",
       "34605  0.651515   0.769231              0.815668  \n",
       "46653  0.115385   0.306122              0.548387  \n",
       "32978  0.290000   0.464789              0.443548  \n",
       "68038  0.278378   0.423729              0.603687  \n",
       "\n",
       "[10 rows x 28 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cb691ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING TESTING TESTING\n",
    "df = df.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e19c0539",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e11feb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Set:  (100, 27)\n",
      "Label Set:  (100,)\n"
     ]
    }
   ],
   "source": [
    "y = df.target\n",
    "X = df.drop('target', axis=1)\n",
    "print(\"Feature Set: \", X.shape)\n",
    "print(\"Label Set: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7f32448",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Feature Set:  (80, 27)\n",
      "Training Label Set:  (80,)\n",
      "Testing Feature Set:  (20, 27)\n",
      "Testing Label Set:  (20,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=1)\n",
    "print(\"Training Feature Set: \", X_train.shape)\n",
    "print(\"Training Label Set: \", y_train.shape)\n",
    "print(\"Testing Feature Set: \", X_test.shape)\n",
    "print(\"Testing Label Set: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a195e9",
   "metadata": {},
   "source": [
    "### Base-Model 1: Exported TPOT Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53dfd0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model_1(X_train, y_train, X_test, export=False):\n",
    "    exported_pipeline = make_pipeline(\n",
    "        MaxAbsScaler(),\n",
    "        MinMaxScaler(),\n",
    "        RandomForestClassifier(\n",
    "            bootstrap=False,\n",
    "            criterion=\"gini\",\n",
    "            max_features=0.25,\n",
    "            min_samples_leaf=1,\n",
    "            min_samples_split=4,\n",
    "            n_estimators=100)\n",
    "    )\n",
    "    exported_pipeline.fit(X_train, y_train)\n",
    "    if export==True:\n",
    "        return exported_pipeline\n",
    "    else:\n",
    "        y_pred = exported_pipeline.predict_proba(X_test)\n",
    "        return [p[1] for p in y_pred]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4382027c",
   "metadata": {},
   "source": [
    "### Base-Model 2: Deep LSTM Siamese Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ddc5c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow based implementation of deep siamese LSTM network.\n",
    "# Taken from https://github.com/dhwajraj/deep-siamese-text-similarity as of 2020-07-20\n",
    "# and modified to fit hmni prediction pipeline\n",
    "# deep-siamese-text-similarity original copyright:\n",
    "#\n",
    "# MIT License\n",
    "#\n",
    "# Copyright (c) 2016 Dhwaj Raj\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "class SiameseLSTM(object):\n",
    "    \"\"\"\n",
    "    A LSTM based deep Siamese network for text similarity.\n",
    "    Uses an character embedding layer, followed by a biLSTM and Energy Loss layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def BiRNN(self, x, dropout, scope, hidden_units):\n",
    "        n_hidden = hidden_units\n",
    "        n_layers = 3\n",
    "\n",
    "        # Prepare data shape to match `static_rnn` function requirements\n",
    "        x = tf.unstack(tf.transpose(x, perm=[1, 0, 2]))\n",
    "\n",
    "        # Define lstm cells with tensorflow\n",
    "        # Forward direction cell\n",
    "        with tf.name_scope('fw' + scope):\n",
    "            with tf.compat.v1.variable_scope('fw' + scope):\n",
    "                stacked_rnn_fw = []\n",
    "                for _ in range(n_layers):\n",
    "                    fw_cell = tf.compat.v1.nn.rnn_cell.LSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "                    lstm_fw_cell = \\\n",
    "                        tf.compat.v1.nn.rnn_cell.DropoutWrapper(fw_cell, output_keep_prob=dropout)\n",
    "                    stacked_rnn_fw.append(lstm_fw_cell)\n",
    "                lstm_fw_cell_m = \\\n",
    "                    tf.compat.v1.nn.rnn_cell.MultiRNNCell(cells=stacked_rnn_fw, state_is_tuple=True)\n",
    "\n",
    "        with tf.name_scope('bw' + scope):\n",
    "            with tf.compat.v1.variable_scope('bw' + scope):\n",
    "                stacked_rnn_bw = []\n",
    "                for _ in range(n_layers):\n",
    "                    bw_cell = tf.compat.v1.nn.rnn_cell.LSTMCell(n_hidden, forget_bias=1.0, state_is_tuple=True)\n",
    "                    lstm_bw_cell = \\\n",
    "                        tf.compat.v1.nn.rnn_cell.DropoutWrapper(bw_cell, output_keep_prob=dropout)\n",
    "                    stacked_rnn_bw.append(lstm_bw_cell)\n",
    "                lstm_bw_cell_m = \\\n",
    "                    tf.compat.v1.nn.rnn_cell.MultiRNNCell(cells=stacked_rnn_bw, state_is_tuple=True)\n",
    "\n",
    "        # Get lstm cell output\n",
    "        with tf.name_scope('bw' + scope):\n",
    "            with tf.compat.v1.variable_scope('bw' + scope):\n",
    "                (outputs, _, _) = \\\n",
    "                    tf.compat.v1.nn.static_bidirectional_rnn(lstm_fw_cell_m,\n",
    "                                                   lstm_bw_cell_m, x, dtype=tf.float32)\n",
    "        return outputs[-1]\n",
    "\n",
    "    def contrastive_loss(self, y, d, batch_size):\n",
    "        tmp = y * tf.square(d)\n",
    "        tmp2 = (1 - y) * tf.square(tf.maximum(1 - d, 0))\n",
    "        return tf.reduce_sum(tmp + tmp2) / batch_size / 2\n",
    "\n",
    "    def __init__(self, sequence_length, vocab_size, embedding_size, hidden_units, batch_size):\n",
    "\n",
    "        # Placeholders for input, output and dropout\n",
    "        self.input_x1 = tf.compat.v1.placeholder(tf.int32, [None, sequence_length], name='input_x1')\n",
    "        self.input_x2 = tf.compat.v1.placeholder(tf.int32, [None, sequence_length], name='input_x2')\n",
    "        self.input_y = tf.compat.v1.placeholder(tf.float32, [None], name='input_y')\n",
    "        self.dropout_keep_prob = tf.compat.v1.placeholder(tf.float32, name='dropout_keep_prob')\n",
    "\n",
    "        # Embedding layer\n",
    "        with tf.name_scope('embedding'):\n",
    "            self.W = tf.Variable(tf.compat.v1.random_uniform([vocab_size, embedding_size], -1.0, 1.0),\n",
    "                                 trainable=True, name='W')\n",
    "            self.embedded_chars1 = tf.nn.embedding_lookup(self.W, self.input_x1)\n",
    "\n",
    "            self.embedded_chars2 = tf.nn.embedding_lookup(self.W, self.input_x2)\n",
    "\n",
    "        # Create a convolution + maxpool layer for each filter size\n",
    "        with tf.name_scope('output'):\n",
    "            self.out1 = self.BiRNN(\n",
    "                self.embedded_chars1,\n",
    "                self.dropout_keep_prob,\n",
    "                'side1',\n",
    "                hidden_units\n",
    "            )\n",
    "            self.out2 = self.BiRNN(\n",
    "                self.embedded_chars2,\n",
    "                self.dropout_keep_prob,\n",
    "                'side2',\n",
    "                hidden_units\n",
    "            )\n",
    "            self.distance = \\\n",
    "                tf.sqrt(tf.reduce_sum(tf.square(tf.subtract(self.out1, self.out2)), 1, keepdims=True))\n",
    "            self.distance = tf.compat.v1.div(self.distance,\n",
    "                                   tf.add(tf.sqrt(tf.reduce_sum(tf.square(self.out1), 1, keepdims=True)),\n",
    "                                          tf.sqrt(tf.reduce_sum(tf.square(self.out2), 1, keepdims=True))))\n",
    "            self.distance = tf.reshape(self.distance, [-1], name='distance')\n",
    "        with tf.name_scope('loss'):\n",
    "            self.loss = self.contrastive_loss(self.input_y, self.distance, batch_size)\n",
    "\n",
    "        # Accuracy computation is outside of this class.\n",
    "        with tf.name_scope('accuracy'):\n",
    "            self.temp_sim = tf.subtract(tf.ones_like(self.distance),\n",
    "                                        tf.compat.v1.rint(self.distance), name='temp_sim')  # auto threshold 0.5\n",
    "            correct_predictions = tf.equal(self.temp_sim, self.input_y)\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, 'float'), name='accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de3794f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow based implementation of deep siamese LSTM network.\n",
    "# Taken from https://github.com/dhwajraj/deep-siamese-text-similarity as of 2020-07-20\n",
    "# and modified to fit hmni prediction pipeline\n",
    "# deep-siamese-text-similarity original copyright:\n",
    "#\n",
    "# MIT License\n",
    "#\n",
    "# Copyright (c) 2016 Dhwaj Raj\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "TOKENIZER_RE = re.compile(r\"[A-Z]{2,}(?![a-z])|[A-Z][a-z]+(?=[A-Z])|[\\'\\w\\-]+\", re.UNICODE)\n",
    "\n",
    "\n",
    "def tokenizer(iterator):\n",
    "    \"\"\"Tokenizer generator.\n",
    "    Args:\n",
    "      iterator: Input iterator with strings.\n",
    "    Yields:\n",
    "      array of tokens per each value in the input.\n",
    "    \"\"\"\n",
    "    for value in iterator:\n",
    "        yield TOKENIZER_RE.findall(value)\n",
    "\n",
    "\n",
    "class CategoricalVocabulary(object):\n",
    "    \"\"\"Categorical variables vocabulary class.\n",
    "  Accumulates and provides mapping from classes to indexes.\n",
    "  Can be easily used for words.\n",
    "  \"\"\"\n",
    "    def __init__(self, unknown_token=\"<UNK>\", support_reverse=True):\n",
    "        self._unknown_token = unknown_token\n",
    "        self._mapping = {unknown_token: 0}\n",
    "        self._support_reverse = support_reverse\n",
    "        if support_reverse:\n",
    "            self._reverse_mapping = [unknown_token]\n",
    "        self._freq = collections.defaultdict(int)\n",
    "        self._freeze = False\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns total count of mappings. Including unknown token.\"\"\"\n",
    "        return len(self._mapping)\n",
    "\n",
    "    def freeze(self, freeze=True):\n",
    "        \"\"\"Freezes the vocabulary, after which new words return unknown token id.\n",
    "        Args:\n",
    "          freeze: True to freeze, False to unfreeze.\n",
    "        \"\"\"\n",
    "        self._freeze = freeze\n",
    "\n",
    "    def get(self, category):\n",
    "        \"\"\"Returns word's id in the vocabulary.\n",
    "        If category is new, creates a new id for it.\n",
    "        Args:\n",
    "          category: string or integer to lookup in vocabulary.\n",
    "        Returns:\n",
    "          interger, id in the vocabulary.\n",
    "        \"\"\"\n",
    "        if category not in self._mapping:\n",
    "            if self._freeze:\n",
    "                return 0\n",
    "            self._mapping[category] = len(self._mapping)\n",
    "            if self._support_reverse:\n",
    "                self._reverse_mapping.append(category)\n",
    "        return self._mapping[category]\n",
    "\n",
    "    def add(self, category, count=1):\n",
    "        \"\"\"Adds count of the category to the frequency table.\n",
    "        Args:\n",
    "          category: string or integer, category to add frequency to.\n",
    "          count: optional integer, how many to add.\n",
    "        \"\"\"\n",
    "        category_id = self.get(category)\n",
    "        if category_id <= 0:\n",
    "            return\n",
    "        self._freq[category] += count\n",
    "\n",
    "    def trim(self, min_frequency, max_frequency=-1):\n",
    "        \"\"\"Trims vocabulary for minimum frequency.\n",
    "        Remaps ids from 1..n in sort frequency order.\n",
    "        where n - number of elements left.\n",
    "        Args:\n",
    "          min_frequency: minimum frequency to keep.\n",
    "          max_frequency: optional, maximum frequency to keep.\n",
    "            Useful to remove very frequent categories (like stop words).\n",
    "        \"\"\"\n",
    "        # Sort by alphabet then reversed frequency.\n",
    "        self._freq = sorted(\n",
    "            sorted(\n",
    "                self._freq.items(),\n",
    "                key=lambda x: (isinstance(x[0], str), x[0])),\n",
    "            key=lambda x: x[1],\n",
    "            reverse=True)\n",
    "        self._mapping = {self._unknown_token: 0}\n",
    "        if self._support_reverse:\n",
    "            self._reverse_mapping = [self._unknown_token]\n",
    "        idx = 1\n",
    "        for category, count in self._freq:\n",
    "            if 0 < max_frequency <= count:\n",
    "                continue\n",
    "            if count <= min_frequency:\n",
    "                break\n",
    "            self._mapping[category] = idx\n",
    "            idx += 1\n",
    "            if self._support_reverse:\n",
    "                self._reverse_mapping.append(category)\n",
    "        self._freq = dict(self._freq[:idx - 1])\n",
    "\n",
    "    def reverse(self, class_id):\n",
    "        \"\"\"Given class id reverse to original class name.\n",
    "        Args:\n",
    "          class_id: Id of the class.\n",
    "        Returns:\n",
    "          Class name.\n",
    "        Raises:\n",
    "          ValueError: if this vocabulary wasn't initialized with support_reverse.\n",
    "        \"\"\"\n",
    "        if not self._support_reverse:\n",
    "            raise ValueError(\"This vocabulary wasn't initialized with \"\n",
    "                             \"support_reverse to support reverse() function.\")\n",
    "        return self._reverse_mapping[class_id]\n",
    "\n",
    "\n",
    "class VocabularyProcessor(object):\n",
    "    \"\"\"Maps documents to sequences of word ids.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 max_document_length,\n",
    "                 min_frequency=0,\n",
    "                 vocabulary=None,\n",
    "                 tokenizer_fn=None):\n",
    "        \"\"\"Initializes a VocabularyProcessor instance.\n",
    "        Args:\n",
    "          max_document_length: Maximum length of documents.\n",
    "            if documents are longer, they will be trimmed, if shorter - padded.\n",
    "          min_frequency: Minimum frequency of words in the vocabulary.\n",
    "          vocabulary: CategoricalVocabulary object.\n",
    "        Attributes:\n",
    "          vocabulary_: CategoricalVocabulary object.\n",
    "        \"\"\"\n",
    "        self.max_document_length = max_document_length\n",
    "        self.min_frequency = min_frequency\n",
    "        if vocabulary:\n",
    "            self.vocabulary_ = vocabulary\n",
    "        else:\n",
    "            self.vocabulary_ = CategoricalVocabulary()\n",
    "        if tokenizer_fn:\n",
    "            self._tokenizer = tokenizer_fn\n",
    "        else:\n",
    "            self._tokenizer = tokenizer\n",
    "\n",
    "    def fit(self, raw_documents):\n",
    "        \"\"\"Learn a vocabulary dictionary of all tokens in the raw documents.\n",
    "        Args:\n",
    "          raw_documents: An iterable which yield either str or unicode.\n",
    "        Returns:\n",
    "          self\n",
    "        \"\"\"\n",
    "        for tokens in self._tokenizer(raw_documents):\n",
    "            for token in tokens:\n",
    "                self.vocabulary_.add(token)\n",
    "        if self.min_frequency > 0:\n",
    "            self.vocabulary_.trim(self.min_frequency)\n",
    "        self.vocabulary_.freeze()\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, raw_documents):\n",
    "        \"\"\"Learn the vocabulary dictionary and return indexies of words.\n",
    "        Args:\n",
    "          raw_documents: An iterable which yield either str or unicode.\n",
    "        Returns:\n",
    "          x: iterable, [n_samples, max_document_length]. Word-id matrix.\n",
    "        \"\"\"\n",
    "        self.fit(raw_documents)\n",
    "        return self.transform(raw_documents)\n",
    "\n",
    "    def transform(self, raw_documents):\n",
    "        \"\"\"Transform documents to word-id matrix.\n",
    "        Convert words to ids with vocabulary fitted with fit or the one\n",
    "        provided in the constructor.\n",
    "        Args:\n",
    "          raw_documents: An iterable which yield either str or unicode.\n",
    "        Yields:\n",
    "          x: iterable, [n_samples, max_document_length]. Word-id matrix.\n",
    "        \"\"\"\n",
    "        for tokens in self._tokenizer(raw_documents):\n",
    "            word_ids = np.zeros(self.max_document_length, np.int64)\n",
    "            for idx, token in enumerate(tokens):\n",
    "                if idx >= self.max_document_length:\n",
    "                    break\n",
    "                word_ids[idx] = self.vocabulary_.get(token)\n",
    "            yield word_ids\n",
    "\n",
    "    def save(self, filename):\n",
    "        \"\"\"Saves vocabulary processor into given file.\n",
    "        Args:\n",
    "          filename: Path to output file.\n",
    "        \"\"\"\n",
    "        with gfile.Open(filename, 'wb') as f:\n",
    "            f.write(pickle.dumps(self))\n",
    "\n",
    "    @classmethod\n",
    "    def restore(cls, filename):\n",
    "        \"\"\"Restores vocabulary processor from given file.\n",
    "        Args:\n",
    "          filename: Path to file to load from.\n",
    "        Returns:\n",
    "          VocabularyProcessor object.\n",
    "        \"\"\"\n",
    "        with gfile.Open(filename, 'rb') as f:\n",
    "            return pickle.loads(f.read())\n",
    "\n",
    "\n",
    "def tokenizer_char(iterator):\n",
    "    for value in iterator:\n",
    "        yield list(value)\n",
    "\n",
    "\n",
    "class MyVocabularyProcessor(VocabularyProcessor):\n",
    "    def __init__(self, max_document_length, min_frequency=0, vocabulary=None):\n",
    "        super().__init__(max_document_length, min_frequency, vocabulary)\n",
    "        sup = super(MyVocabularyProcessor, self)\n",
    "        sup.__init__(max_document_length, min_frequency, vocabulary,\n",
    "                     tokenizer_char)\n",
    "\n",
    "    def transform(self, raw_documents):\n",
    "        \"\"\"Transform documents to word-id matrix.\n",
    "        Convert words to ids with vocabulary fitted with fit or the one\n",
    "        provided in the constructor.\n",
    "        Args:\n",
    "          raw_documents: An iterable which yield either str or unicode.\n",
    "        Yields:\n",
    "          x: iterable, [n_samples, max_document_length]. Word-id matrix.\n",
    "        \"\"\"\n",
    "        for tokens in self._tokenizer(raw_documents):\n",
    "            word_ids = np.zeros(self.max_document_length, np.int64)\n",
    "            for (idx, token) in enumerate(tokens):\n",
    "                if idx >= self.max_document_length:\n",
    "                    break\n",
    "                word_ids[idx] = self.vocabulary_.get(token)\n",
    "            yield word_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3244a3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model_2(X_train, y_train, X_test, export=False):\n",
    "    \n",
    "    # Train Model\n",
    "    embedding_dim = 300  # Dimensionality of character embedding\n",
    "    dropout_keep_prob = 0.8  # Dropout keep probability\n",
    "    hidden_units = 50\n",
    "    batch_size = 64\n",
    "    num_epochs = 300  # Number of training epochs\n",
    "    evaluate_every = 1000  # Evaluate model on dev set after this many steps\n",
    "    max_document_length = 15\n",
    "    out_dir = os.getcwd()+'\\\\'  # where to save exported models\n",
    "\n",
    "    inpH = InputHelper()\n",
    "    train_set, dev_set, vocab_processor, sum_no_of_batches = \\\n",
    "        inpH.get_datasets(\n",
    "        X_train[['name_a', 'name_b']],\n",
    "        y_train,\n",
    "        max_document_length=max_document_length,\n",
    "        percent_dev=10,\n",
    "        batch_size=64)\n",
    "\n",
    "\n",
    "    # print('starting graph def')\n",
    "    graph = tf.Graph()\n",
    "    with tf.Graph().as_default():\n",
    "        session_conf = tf.compat.v1.ConfigProto(allow_soft_placement=True, log_device_placement=False)\n",
    "        sess = tf.compat.v1.Session(config=session_conf)\n",
    "        # print('started session')\n",
    "        with sess.as_default():\n",
    "            siameseModel = SiameseLSTM(\n",
    "                sequence_length=max_document_length,\n",
    "                vocab_size=len(vocab_processor.vocabulary_),\n",
    "                embedding_size=embedding_dim,\n",
    "                hidden_units=hidden_units,\n",
    "                batch_size=batch_size,\n",
    "            )\n",
    "\n",
    "            # Define Training procedure\n",
    "            global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "            # optimizer = tf.optimizers.Adam(1e-3)\n",
    "            # optimizer = Adam(1e-3)\n",
    "            optimizer = tf.compat.v1.train.AdamOptimizer(1e-3)\n",
    "            # print('initialized siameseModel object')\n",
    "\n",
    "        grads_and_vars = optimizer.compute_gradients(siameseModel.loss)\n",
    "        tr_op_set = optimizer.apply_gradients(grads_and_vars, global_step=global_step)\n",
    "        # print('defined training_ops')\n",
    "        \n",
    "        if export==True:\n",
    "            saver = tf.compat.v1.train.Saver(tf.compat.v1.global_variables(), max_to_keep=100)\n",
    "            # Write vocabulary\n",
    "            vocab_processor.save(os.path.join(out_dir, 'vocab'))\n",
    "\n",
    "        # Initialize all variables\n",
    "        sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "        def train_step(x1_batch, x2_batch, y_batch):\n",
    "            # A single training step\n",
    "            if random.random() > 0.5:\n",
    "                feed_dict = {\n",
    "                    siameseModel.input_x1: x1_batch,\n",
    "                    siameseModel.input_x2: x2_batch,\n",
    "                    siameseModel.input_y: y_batch,\n",
    "                    siameseModel.dropout_keep_prob: dropout_keep_prob,\n",
    "                }\n",
    "            else:\n",
    "                feed_dict = {\n",
    "                    siameseModel.input_x1: x2_batch,\n",
    "                    siameseModel.input_x2: x1_batch,\n",
    "                    siameseModel.input_y: y_batch,\n",
    "                    siameseModel.dropout_keep_prob: dropout_keep_prob,\n",
    "                }\n",
    "            (_, step, loss, accuracy, dist, sim) = \\\n",
    "                sess.run([tr_op_set, global_step, siameseModel.loss, siameseModel.accuracy,\n",
    "                          siameseModel.distance, siameseModel.temp_sim], feed_dict)\n",
    "\n",
    "        def dev_step(x1_batch, x2_batch, y_batch):\n",
    "            # A single training step\n",
    "            if random.random() > 0.5:\n",
    "                feed_dict = {\n",
    "                    siameseModel.input_x1: x1_batch,\n",
    "                    siameseModel.input_x2: x2_batch,\n",
    "                    siameseModel.input_y: y_batch,\n",
    "                    siameseModel.dropout_keep_prob: 1.0,\n",
    "                }\n",
    "            else:\n",
    "                feed_dict = {\n",
    "                    siameseModel.input_x1: x2_batch,\n",
    "                    siameseModel.input_x2: x1_batch,\n",
    "                    siameseModel.input_y: y_batch,\n",
    "                    siameseModel.dropout_keep_prob: 1.0,\n",
    "                }\n",
    "            (step, loss, accuracy, sim) = \\\n",
    "                sess.run([global_step, siameseModel.loss, siameseModel.accuracy,\n",
    "                          siameseModel.temp_sim], feed_dict)\n",
    "            return accuracy\n",
    "\n",
    "        # Generate batches\n",
    "        batches = inpH.batch_iter(list(zip(train_set[0], train_set[1],\n",
    "                                           train_set[2])), batch_size, num_epochs)\n",
    "        max_validation_acc = 0.0\n",
    "        for nn in range(sum_no_of_batches * num_epochs):\n",
    "            batch = next(batches)\n",
    "            if len(batch) < 1:\n",
    "                continue\n",
    "            (x1_batch, x2_batch, y_batch) = zip(*batch)\n",
    "            if len(y_batch) < 1:\n",
    "                continue\n",
    "            train_step(x1_batch, x2_batch, y_batch)\n",
    "            current_step = tf.compat.v1.train.global_step(sess, global_step)\n",
    "            sum_acc = 0.0\n",
    "            if current_step % evaluate_every == 0:\n",
    "                dev_batches = inpH.batch_iter(list(zip(dev_set[0], dev_set[1], dev_set[2])), batch_size, 1)\n",
    "                for db in dev_batches:\n",
    "                    if len(db) < 1:\n",
    "                        continue\n",
    "                    (x1_dev_b, x2_dev_b, y_dev_b) = zip(*db)\n",
    "                    if len(y_dev_b) < 1:\n",
    "                        continue\n",
    "                    acc = dev_step(x1_dev_b, x2_dev_b, y_dev_b)\n",
    "                    sum_acc = sum_acc + acc\n",
    "            if sum_acc > max_validation_acc:\n",
    "                max_validation_acc = sum_acc\n",
    "            \n",
    "                if export==True:\n",
    "                    # save model\n",
    "                    saver.save(sess, out_dir, global_step=current_step)\n",
    "                    tf.train.write_graph(sess.graph.as_graph_def(), out_dir, 'siamese_network.pb', as_text=False)\n",
    "                \n",
    "                # print('model {} with sum_accuracy={}'.format(nn, max_validation_acc))     \n",
    "        if export==True:\n",
    "            return\n",
    "        \n",
    "        # RUN OOF INFERENCE\n",
    "        x1_temp= np.asarray(X_test['name_a'].tolist())\n",
    "        x2_temp= np.asarray(X_test['name_b'].tolist())\n",
    "        \n",
    "        x1 = np.asarray(list(vocab_processor.transform(x1_temp)))\n",
    "        x2 = np.asarray(list(vocab_processor.transform(x2_temp)))\n",
    "\n",
    "        (predictions, sim) = sess.run([siameseModel.distance, siameseModel.temp_sim], {\n",
    "                siameseModel.input_x1: x1,\n",
    "                siameseModel.input_x2: x2,\n",
    "                siameseModel.dropout_keep_prob: 1.0,\n",
    "            })\n",
    "                \n",
    "        sim = predictions.tolist()\n",
    "        sim = [1-x for x in sim]\n",
    "        # print(sim)\n",
    "        return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7d2a560",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow based implementation of deep siamese LSTM network.\n",
    "# Taken from https://github.com/dhwajraj/deep-siamese-text-similarity as of 2020-07-20\n",
    "# and modified to fit hmni prediction pipeline\n",
    "# deep-siamese-text-similarity original copyright:\n",
    "#\n",
    "# MIT License\n",
    "#\n",
    "# Copyright (c) 2016 Dhwaj Raj\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in all\n",
    "# copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "# SOFTWARE.\n",
    "\n",
    "class InputHelper(object):\n",
    "    vocab_processor = None\n",
    "\n",
    "    def batch_iter(\n",
    "            self,\n",
    "            data,\n",
    "            batch_size,\n",
    "            num_epochs,\n",
    "            shuffle=True,\n",
    "    ):\n",
    "\n",
    "        # Generates a batch iterator for a dataset.\n",
    "        data = np.asarray(data)\n",
    "        data_size = len(data)\n",
    "        num_batches_per_epoch = int(len(data) / batch_size) + 1\n",
    "        for epoch in range(num_epochs):\n",
    "\n",
    "            # Shuffle the data at each epoch\n",
    "            if shuffle:\n",
    "                shuffle_indices = \\\n",
    "                    np.random.permutation(np.arange(data_size))\n",
    "                shuffled_data = data[shuffle_indices]\n",
    "            else:\n",
    "                shuffled_data = data\n",
    "            for batch_num in range(num_batches_per_epoch):\n",
    "                start_index = batch_num * batch_size\n",
    "                end_index = min((batch_num + 1) * batch_size, data_size)\n",
    "                yield shuffled_data[start_index:end_index]\n",
    "\n",
    "    # Data Preparation\n",
    "    def get_datasets(\n",
    "            self,\n",
    "            X_train,\n",
    "            y_train,\n",
    "            max_document_length,\n",
    "            percent_dev,\n",
    "            batch_size,\n",
    "    ):\n",
    "        (x1_text, x2_text, y) = \\\n",
    "            np.asarray(X_train.iloc[:, 0].str.lower()), np.asarray(X_train.iloc[:, 1].str.lower()), np.asarray(y_train)\n",
    "\n",
    "        # Build vocabulary\n",
    "        # print('Building vocabulary')\n",
    "        vocab_processor = MyVocabularyProcessor(max_document_length, min_frequency=0)\n",
    "        vocab_processor.fit_transform(np.concatenate((x2_text, x1_text), axis=0))\n",
    "        # print('Length of loaded vocabulary ={}'.format(len(vocab_processor.vocabulary_)))\n",
    "\n",
    "        sum_no_of_batches = 0\n",
    "        x1 = np.asarray(list(vocab_processor.transform(x1_text)))\n",
    "        x2 = np.asarray(list(vocab_processor.transform(x2_text)))\n",
    "\n",
    "        # Randomly shuffle data\n",
    "        np.random.seed(131)\n",
    "        shuffle_indices = np.random.permutation(np.arange(len(y)))\n",
    "        x1_shuffled = x1[shuffle_indices]\n",
    "        x2_shuffled = x2[shuffle_indices]\n",
    "        y_shuffled = y[shuffle_indices]\n",
    "        dev_idx = -1 * len(y_shuffled) * percent_dev // 100\n",
    "        del x1\n",
    "        del x2\n",
    "\n",
    "        # TODO: This is very crude, should use cross-validation\n",
    "        (x1_train, x1_dev) = (x1_shuffled[:dev_idx], x1_shuffled[dev_idx:])\n",
    "        (x2_train, x2_dev) = (x2_shuffled[:dev_idx], x2_shuffled[dev_idx:])\n",
    "        (y_train, y_dev) = (y_shuffled[:dev_idx], y_shuffled[dev_idx:])\n",
    "        # print('Train/Dev split for data: {:d}/{:d}'.format(len(y_train), len(y_dev)))\n",
    "\n",
    "        sum_no_of_batches = sum_no_of_batches + len(y_train) // batch_size\n",
    "        train_set = (x1_train, x2_train, y_train)\n",
    "        dev_set = (x1_dev, x2_dev, y_dev)\n",
    "        gc.collect()\n",
    "        return train_set, dev_set, vocab_processor, sum_no_of_batches\n",
    "\n",
    "    def getTestDataSet(\n",
    "            self,\n",
    "            X_test,\n",
    "            y_test,\n",
    "            vocab,\n",
    "            max_document_length,\n",
    "    ):\n",
    "        (x1_temp, x2_temp, y) = np.asarray(X_test.iloc[:, 0].str.lower()), np.asarray(\n",
    "            X_test.iloc[:, 1].str.lower()), np.asarray(y_test)\n",
    "\n",
    "        # Build vocabulary\n",
    "        vocab_processor = MyVocabularyProcessor(max_document_length, min_frequency=0)\n",
    "        vocab_processor = vocab\n",
    "\n",
    "        x1 = np.asarray(list(vocab_processor.transform(x1_temp)))\n",
    "        x2 = np.asarray(list(vocab_processor.transform(x2_temp)))\n",
    "\n",
    "        # Randomly shuffle data\n",
    "        del vocab_processor\n",
    "        gc.collect()\n",
    "        return x1, x2, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a9422f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mkars\\AppData\\Local\\Temp\\ipykernel_18564\\1653033814.py:51: LSTMCell.__init__ (from tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From C:\\Users\\mkars\\AppData\\Local\\Temp\\ipykernel_18564\\1653033814.py:56: MultiRNNCell.__init__ (from tensorflow.python.keras.layers.legacy_rnn.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From C:\\Users\\mkars\\AppData\\Local\\Temp\\ipykernel_18564\\1653033814.py:73: static_bidirectional_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell, unroll=True))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\mkars\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\rnn.py:1579: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From C:\\Users\\mkars\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:962: Layer.add_variable (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From C:\\Users\\mkars\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\legacy_rnn\\rnn_cell_impl.py:970: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\mkars\\AppData\\Local\\Temp\\ipykernel_18564\\1653033814.py:114: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "completed fold 1 of 10\n",
      "completed fold 2 of 10\n",
      "completed fold 3 of 10\n",
      "completed fold 4 of 10\n",
      "completed fold 5 of 10\n",
      "completed fold 6 of 10\n",
      "completed fold 7 of 10\n",
      "completed fold 8 of 10\n",
      "completed fold 9 of 10\n",
      "completed fold 10 of 10\n"
     ]
    }
   ],
   "source": [
    "# Stratified K-Folds cross-validator\n",
    "meta_training = pd.DataFrame()\n",
    "\n",
    "stratified_kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=1)\n",
    "\n",
    "fold = 1\n",
    "for train_index, test_index in stratified_kfold.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    oof_pred = X_test[['name_a', 'name_b']]\n",
    "    \n",
    "    oof_pred['predict_proba'] = base_model_1(X_train.drop(['a', 'b', 'name_a', 'name_b'], 1),\n",
    "                                      y_train,\n",
    "                                      X_test.drop(['a', 'b', 'name_a', 'name_b'], 1))\n",
    "\n",
    "    oof_pred['siamese_sim'] = base_model_2(X_train[['name_a', 'name_b']],\n",
    "                                      y_train,\n",
    "                                      X_test[['name_a', 'name_b']])\n",
    "    \n",
    "    oof_pred['target'] = y_test.tolist()\n",
    "    \n",
    "    print('completed fold {} of 10'.format(fold))\n",
    "    fold += 1\n",
    "\n",
    "    meta_training = meta_training.append(oof_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b85afd49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name_a</th>\n",
       "      <th>name_b</th>\n",
       "      <th>predict_proba</th>\n",
       "      <th>siamese_sim</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10555</th>\n",
       "      <td>mary</td>\n",
       "      <td>marylou</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.065085</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57876</th>\n",
       "      <td>lode</td>\n",
       "      <td>mikey</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.188817</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60631</th>\n",
       "      <td>trent</td>\n",
       "      <td>radisa</td>\n",
       "      <td>0.028333</td>\n",
       "      <td>0.004510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64563</th>\n",
       "      <td>oleta</td>\n",
       "      <td>dareczek</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011909</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68720</th>\n",
       "      <td>lora</td>\n",
       "      <td>karol</td>\n",
       "      <td>0.063333</td>\n",
       "      <td>0.026410</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85305</th>\n",
       "      <td>anabelle</td>\n",
       "      <td>sigismand</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.706787</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13764</th>\n",
       "      <td>randolph</td>\n",
       "      <td>rand</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.005344</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4159</th>\n",
       "      <td>eliza</td>\n",
       "      <td>besse</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.248512</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78932</th>\n",
       "      <td>sigmund</td>\n",
       "      <td>gerie</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142358</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3166</th>\n",
       "      <td>danny</td>\n",
       "      <td>danielle</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.969730</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name_a     name_b  predict_proba  siamese_sim  target\n",
       "10555      mary    marylou       0.950000     0.065085       1\n",
       "57876      lode      mikey       0.046667     0.188817       0\n",
       "60631     trent     radisa       0.028333     0.004510       0\n",
       "64563     oleta   dareczek       0.000000     0.011909       0\n",
       "68720      lora      karol       0.063333     0.026410       0\n",
       "85305  anabelle  sigismand       0.025000     0.706787       0\n",
       "13764  randolph       rand       0.990000     0.005344       1\n",
       "4159      eliza      besse       0.000000     0.248512       1\n",
       "78932   sigmund      gerie       0.000000     0.142358       0\n",
       "3166      danny   danielle       0.910000     0.969730       1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_training.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d3500b",
   "metadata": {},
   "source": [
    "## Meta-Model: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "759bc365",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def syllables(word):\n",
    "    # single syllable word\n",
    "    if len(re.findall('[aeiouy]', word)) <= 1:\n",
    "        return [word]\n",
    "\n",
    "    # sonority hierarchy: vowels, nasals, fricatives, stops\n",
    "    hierarchy = {\n",
    "        'a': 4, 'e': 4, 'i': 4, 'o': 4, 'u': 4, 'y': 4,\n",
    "        'l': 3, 'm': 3, 'n': 3, 'r': 3, 'w': 3,\n",
    "        'f': 2, 's': 2, 'v': 2, 'z': 2,\n",
    "        'b': 1, 'c': 1, 'd': 1, 'g': 1, 'h': 1, 'j': 1, 'k': 1, 'p': 1, 'q': 1, 't': 1, 'x': 1,\n",
    "    }\n",
    "    syllables_values = [(c, hierarchy[c]) for c in word]\n",
    "\n",
    "    syllables = []\n",
    "    syll = syllables_values[0][0]\n",
    "    for trigram in zip(*[syllables_values[i:] for i in range(3)]):\n",
    "        (phonemes, values) = zip(*trigram)\n",
    "        (previous, val, following) = values\n",
    "        phoneme = phonemes[1]\n",
    "\n",
    "        if previous > val < following:\n",
    "            syllables.append(syll)\n",
    "            syll = phoneme\n",
    "        elif previous >= val == following:\n",
    "            syll += phoneme\n",
    "            syllables.append(syll)\n",
    "            syll = ''\n",
    "        else:\n",
    "            syll += phoneme\n",
    "    syll += syllables_values[-1][0]\n",
    "    syllables.append(syll)\n",
    "\n",
    "    final_syllables = []\n",
    "    front = ''\n",
    "    for (i, syllable) in enumerate(syllables):\n",
    "        if not re.search('[aeiouy]', syllable):\n",
    "            if len(final_syllables) == 0:\n",
    "                front += syllable\n",
    "            else:\n",
    "                final_syllables = final_syllables[:-1] \\\n",
    "                                  + [final_syllables[-1] + syllable]\n",
    "        else:\n",
    "            if len(final_syllables) == 0:\n",
    "                final_syllables.append(front + syllable)\n",
    "            else:\n",
    "                final_syllables.append(syllable)\n",
    "    return final_syllables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dc128f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize(df):\n",
    "    if len(df.columns)==3:\n",
    "        df.columns=['a', 'b', 'target']\n",
    "    elif len(df.columns)==2:\n",
    "        df.columns=['a', 'b']\n",
    "    else:\n",
    "        df = df.rename(columns={df.columns[0]: 'a', df.columns[1]: 'b' })\n",
    "        \n",
    "    df['name_a'] = df.apply(lambda row: re.sub(\n",
    "        '[^a-zA-Z]+', '', unidecode.unidecode(row['a']).lower().strip()), axis=1)\n",
    "    df['name_b'] = df.apply(lambda row: re.sub(\n",
    "        '[^a-zA-Z]+', '', unidecode.unidecode(row['b']).lower().strip()), axis=1)\n",
    "    \n",
    "    df['syll_a'] = df.apply(lambda row: syllables(row.name_a), axis=1)\n",
    "    df['syll_b'] = df.apply(lambda row: syllables(row.name_b), axis=1)\n",
    "    \n",
    "    df['partial'] = df.apply(lambda row: fuzz.partial_ratio(row.syll_a,row.syll_b), axis=1)\n",
    "    df['tkn_sort'] = df.apply(lambda row: fuzz.token_sort_ratio(row.syll_a,row.syll_b), axis=1)\n",
    "    df['tkn_set'] = df.apply(lambda row: fuzz.token_set_ratio(row.syll_a,row.syll_b), axis=1)\n",
    "    \n",
    "    df['sum_ipa'] = df.apply(lambda row: sum_ipa(row.name_a, row.name_b), axis=1)\n",
    "    \n",
    "    df['pshp_soundex_first'] = df.apply(\n",
    "        lambda row: 1 if pshp_soundex_first.encode(row.name_a)==pshp_soundex_first.encode(row.name_b) else 0, axis=1)\n",
    "    \n",
    "    for i, algo in enumerate(algos):\n",
    "            df[algo_names[i]] = df.apply(lambda row: algo.sim(row.name_a, row.name_b), axis=1)\n",
    "            \n",
    "    df.drop(['syll_a', 'syll_b'], axis=1, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1270efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pshp_soundex_first = PSHPSoundexFirst()\n",
    "pe = Ainsworth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee99dc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "iss = IterativeSubString()\n",
    "bisim = BISIM()\n",
    "dlev = DiscountedLevenshtein()\n",
    "prefix = Prefix()\n",
    "lcs = LCSstr()\n",
    "mlipns = MLIPNS()\n",
    "strcmp95 = Strcmp95()\n",
    "mra = MRA()\n",
    "editex = Editex()\n",
    "saps = SAPS()\n",
    "flexmetric = FlexMetric()\n",
    "jaro = JaroWinkler(mode='Jaro')\n",
    "higuera_mico = HigueraMico()\n",
    "sift4 = Sift4()\n",
    "eudex = Eudex()\n",
    "aline = ALINE()\n",
    "covington = Covington()\n",
    "phonetic_edit = PhoneticEditDistance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1de1c46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "algos = [iss, bisim, dlev, prefix, lcs, mlipns, strcmp95, mra, editex, saps, flexmetric, jaro, higuera_mico, sift4, eudex,\n",
    "         aline, covington, phonetic_edit]\n",
    "\n",
    "algo_names = ['iterativesubstring', 'bisim', 'discountedlevenshtein', 'prefix', 'lcsstr', 'mlipns', 'strcmp95', 'mra',\n",
    "              'editex', 'saps', 'flexmetric', 'jaro', 'higueramico', 'sift4', 'eudex', 'aline', 'covington',\n",
    "              'phoneticeditdistance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "644df4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_ipa(name_a, name_b):\n",
    "    feat1 = ipa_to_features(pe.encode(name_a))\n",
    "    feat2 = ipa_to_features(pe.encode(name_b))\n",
    "    score = sum(cmp_features(f1, f2) for f1, f2 in zip(feat1, feat2))/len(feat1)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce06301f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = featurize(meta_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b048e66d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>predict_proba</th>\n",
       "      <th>siamese_sim</th>\n",
       "      <th>target</th>\n",
       "      <th>name_a</th>\n",
       "      <th>name_b</th>\n",
       "      <th>partial</th>\n",
       "      <th>tkn_sort</th>\n",
       "      <th>tkn_set</th>\n",
       "      <th>...</th>\n",
       "      <th>editex</th>\n",
       "      <th>saps</th>\n",
       "      <th>flexmetric</th>\n",
       "      <th>jaro</th>\n",
       "      <th>higueramico</th>\n",
       "      <th>sift4</th>\n",
       "      <th>eudex</th>\n",
       "      <th>aline</th>\n",
       "      <th>covington</th>\n",
       "      <th>phoneticeditdistance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41317</th>\n",
       "      <td>acho</td>\n",
       "      <td>cenia</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.933845</td>\n",
       "      <td>0</td>\n",
       "      <td>acho</td>\n",
       "      <td>cenia</td>\n",
       "      <td>67</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.867157</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.593548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13062</th>\n",
       "      <td>pat</td>\n",
       "      <td>patte</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>0.356006</td>\n",
       "      <td>1</td>\n",
       "      <td>pat</td>\n",
       "      <td>patte</td>\n",
       "      <td>86</td>\n",
       "      <td>67</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.994118</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53784</th>\n",
       "      <td>ilj</td>\n",
       "      <td>hose</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002509</td>\n",
       "      <td>0</td>\n",
       "      <td>ilj</td>\n",
       "      <td>hose</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.618627</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.314286</td>\n",
       "      <td>0.604839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62193</th>\n",
       "      <td>vilmoska</td>\n",
       "      <td>sebastjan</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.043697</td>\n",
       "      <td>0</td>\n",
       "      <td>vilmoska</td>\n",
       "      <td>sebastjan</td>\n",
       "      <td>65</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272222</td>\n",
       "      <td>0.490741</td>\n",
       "      <td>0.188889</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.696078</td>\n",
       "      <td>0.425490</td>\n",
       "      <td>0.535294</td>\n",
       "      <td>0.702509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40015</th>\n",
       "      <td>zeland</td>\n",
       "      <td>liz</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.049105</td>\n",
       "      <td>0</td>\n",
       "      <td>zeland</td>\n",
       "      <td>liz</td>\n",
       "      <td>57</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.799510</td>\n",
       "      <td>0.308824</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.467742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              a          b  predict_proba  siamese_sim  target    name_a  \\\n",
       "41317      acho      cenia       0.025000     0.933845       0      acho   \n",
       "13062       pat      patte       0.855000     0.356006       1       pat   \n",
       "53784       ilj       hose       0.000000     0.002509       0       ilj   \n",
       "62193  vilmoska  sebastjan       0.030000     0.043697       0  vilmoska   \n",
       "40015    zeland        liz       0.006667     0.049105       0    zeland   \n",
       "\n",
       "          name_b  partial  tkn_sort  tkn_set  ...    editex      saps  \\\n",
       "41317      cenia       67        36       36  ...  0.200000  0.000000   \n",
       "13062      patte       86        67      100  ...  0.800000  0.266667   \n",
       "53784       hose       43         0        0  ...  0.125000  0.000000   \n",
       "62193  sebastjan       65        29       29  ...  0.222222  0.000000   \n",
       "40015        liz       57        40       40  ...  0.250000  0.000000   \n",
       "\n",
       "       flexmetric      jaro  higueramico     sift4     eudex     aline  \\\n",
       "41317    0.160000  0.483333     0.133333  0.200000  0.867157  0.304348   \n",
       "13062    0.900000  0.866667     0.550000  0.600000  0.994118  0.703704   \n",
       "53784    0.175000  0.000000     0.000000  0.000000  0.618627  0.200000   \n",
       "62193    0.272222  0.490741     0.188889  0.222222  0.696078  0.425490   \n",
       "40015    0.366667  0.500000     0.050000  0.166667  0.799510  0.308824   \n",
       "\n",
       "       covington  phoneticeditdistance  \n",
       "41317   0.466667              0.593548  \n",
       "13062   0.756410              0.600000  \n",
       "53784   0.314286              0.604839  \n",
       "62193   0.535294              0.702509  \n",
       "40015   0.465116              0.467742  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a61dff",
   "metadata": {},
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "029bb23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [col for col in df.columns if col not in ['a', 'b', 'name_a', 'name_b', 'target', 'predict_proba', 'siamese_sim']]\n",
    "comb2 = list(combinations(cols, 2))\n",
    "comb3 = list(combinations(cols, 3))\n",
    "colgrid = [(col,)for col in cols]+comb2+comb3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c7ae6e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, df.target, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "358e4406",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver='liblinear')\n",
    "grid_clf = GridSearchCV(clf, param_grid = {'C':np.logspace(-4, 4, 20)}, scoring = 'precision', verbose=0)\n",
    "\n",
    "scores = []\n",
    "for cols in colgrid:\n",
    "    grid_clf.fit(X_train[['predict_proba', 'siamese_sim']+list(cols)], y_train)\n",
    "    y_pred = grid_clf.predict(X_val[['predict_proba', 'siamese_sim']+list(cols)])\n",
    "    tn, fp, fn, tp = confusion_matrix(y_val, y_pred).ravel()\n",
    "    scores.append([str(cols), tn, fp, fn, tp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ffb2430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = pd.DataFrame(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d5ee878",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df.columns = ['features', 'tn', 'fp', 'fn', 'tp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5960d38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('partial',)</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('tkn_sort',)</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('tkn_set',)</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>('sum_ipa',)</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>('pshp_soundex_first',)</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  features  tn  fp  fn  tp\n",
       "0             ('partial',)  16   0   3   1\n",
       "1            ('tkn_sort',)  16   0   3   1\n",
       "2             ('tkn_set',)  16   0   4   0\n",
       "3             ('sum_ipa',)  16   0   3   1\n",
       "4  ('pshp_soundex_first',)  16   0   3   1"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a71571c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df['error'] = scores_df['fp'] + scores_df['fn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7d7cf01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_df = scores_df.sort_values(['error', 'fp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7f015a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, df.target, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2881de8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_cols = ['predict_proba', 'siamese_sim', 'tkn_set', 'iterativesubstring', 'strcmp95']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e7635f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(solver='liblinear')\n",
    "grid_clf = GridSearchCV(clf, param_grid = {'C':np.logspace(-4, 4, 20)}, scoring='precision')\n",
    "grid_clf.fit(X_train[selected_cols], y_train)\n",
    "y_pred = grid_clf.predict(X_test[selected_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0ed7bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.615848211066026}\n"
     ]
    }
   ],
   "source": [
    "print(grid_clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e06de3",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "51c36f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_test, y_pred):\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    conf_matrix = pd.DataFrame(data=cm, columns=['Predicted: 0', 'Predicted: 1'], index=['Actual: 0', 'Actual: 1'])\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1156e2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        17\n",
      "           1       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.88      0.97      0.91        20\n",
      "weighted avg       0.96      0.95      0.95        20\n",
      "\n",
      "           Predicted: 0  Predicted: 1\n",
      "Actual: 0            16             1\n",
      "Actual: 1             0             3\n"
     ]
    }
   ],
   "source": [
    "evaluate(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2fca8231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.6, 0.3, 'AUC=0.941')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmYAAAJ1CAYAAABzbjy/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB/tklEQVR4nO3dd1gU5/428HvpTVBAkSagooIVsPdu7F0UKRqT6C8nUWOa0SSWFE05KSYxVQUEEXuJ2BI7moiIFbsiFhBB6Z193j982cPS3MWFWeD+XNdeyU79zs6we/vMzDMyIYQAEREREUlOR+oCiIiIiOgZBjMiIiIiLcFgRkRERKQlGMyIiIiItASDGREREZGWYDAjIiIi0hIMZkRERERagsGMiIiISEswmBERERFpCQYzokrExcVBJpPB2dlZ6lKohjk7O0MmkyEuLk7qUqqNTCaDTCaTuox6Z+nSpZDJZFi6dGm1r6s+HMd1DYMZaUzxF0DJl5GREVxcXODr64uoqCipSyQAx44dw4wZM9C8eXOYmJjAwsIC7dq1w4IFC3Dr1i2py6sRO3bswNKlS3Hu3DmpS9GYjIwMfPPNNxg0aBBsbW1hYGAACwsLdOrUCXPnzsXZs2elLlFrpKamYunSpfjuu++kLuWF1MXjmBjMqBq4urqiV69e6NWrF1xdXZGYmIjQ0FD06NED69evl7o8tejr66N169Zo0aKF1KW8sPz8fAQEBKBfv34ICgrC06dP4ebmBgcHB1y7dg3ffvst3N3da/2PlSp27NiBZcuWVfqD1qJFC7Ru3Rr6+vo1V1gV7d27F82bN8fbb7+NQ4cOQVdXFx07doS9vT2uXbuGH374AV5eXnjjjTekLlUrpKamYtmyZZId69bW1mjdujWsra1faDl17Tim/08QaYiTk5MAINatW6c0/MmTJ2LSpEkCgGjQoIF48uSJNAXWc2PHjhUAhLW1tQgNDRUFBQWKcY8fPxbz5s0TAAQA8c0330hYafULCAgo91itjXbt2iV0dXUFADF16lRx9epVpfGZmZkiNDRUtG7dWnTs2FFpXPH+rm/u3LkjAAgnJyepS3khdek4pv9hixlVu0aNGmHNmjUwNTVFRkYGDhw4IHVJ9c6vv/6KnTt3wtTUFIcOHYKPjw/09PQU462trfHdd98prnl5//33cenSJYmqJVUlJSUhICAARUVFeO+99xAWFobWrVsrTWNqagofHx+cP38eM2fOlKhSIlKZ1MmQ6o6KWsyKeXh4CABi5cqV5Y7ft2+fGD16tGjSpIkwMDAQ9vb2YsaMGeLmzZsVrjMrK0t89dVXolu3bsLCwkIYGxuLli1bCl9fX3HkyJEy08vlchEWFiYGDx4sLC0thYGBgXBxcRFvvvmmSEhIKDN9ef+yvnTpkgAgGjVqJPLy8iqszdPTUwAQO3fufKEaDh8+LACIfv36iYKCAvHFF1+Idu3aCWNjY5X+xV9YWKjYN5999tlzp3V3dxcAhK+vr9K4devWCQAiICBApKeni7feeks4OTkJQ0ND4eLiIhYtWiSysrIqXHZKSopYtGiRaNu2rTAxMRFmZmaiW7du4rfffhNFRUVlpi/ZGnD79m0REBAg7OzshK6urliyZImi3h07doiZM2cKd3d3YW5uLoyNjUWbNm3Eu+++Kx4/fqy0zOL9WdGreLlC/O94vnPnjtIy+vXrJwCIw4cPiytXrohJkyYJKysrYWRkJDw9PUV4eHiFn0F6erp49913FZ+bs7OzeO+990RmZmaVWj8++ugjAUC0bdtWqQVUVSjRYhYRESH69OkjzMzMhLm5uXjppZfE2bNny53v4sWL4uOPPxbdu3cXTZs2Ffr6+qJp06Zi/PjxIjIystx5Sh4/mZmZ4oMPPhCurq7C0NBQ9OvXTzHdqVOnxLvvviu8vLxE48aNhYGBgXBwcBC+vr7i0qVLlW7P1atXxauvvipatGghjIyMhKWlpfD09BQff/yxePjwoRDif8dVRa/Srly5ImbOnCmcnJyEgYGBsLS0FCNGjBB///13uTWUPG4OHTokXnrpJWFlZaU4ZoQQYsmSJWWOt2K7du0SQ4cOFVZWVkJPT09YW1uL9u3bizfeeEPExsYKITRzHBc7cOCAGD9+vLC1tRUGBgbC1tZW9O/fX/z4448iNze30s+bqgeDGWnM84JZ69atBQCxatWqMuNKnkZr0qSJ8PDwEObm5gKAMDc3L/fL/u7du8LNzU0xn6urq/D09BSWlpaKIFNSfn6+mDx5smJ6Ozs70bFjR2FiYiIACFtbW3Ht2jWleSo65dG+fXsBQOzatavcbb127Vq54a0qNRQHs759+4qRI0cKAKJFixbCy8tLtG3bttz1lxQZGSkACD09vTJBpTzffvutACBMTEyUfuyLf1inTp0qPDw8hEwmE23bthXt2rUTMplMABDdu3cvN5xdunRJ2NvbCwDCwMBAuLu7ixYtWijmmzRpkpDL5UrzFP+ALly4UDRs2FAYGhoKT09P0aZNG7F06VIhhBD37t0TAISOjo6wtbVVjDcyMhIAhLOzs0hMTFQsMyEhQfTq1Us0adJEccz06tVL8VqzZo1i2ucFs6+//lqYmZmJBg0aKEJE8X5dv359mc8gLS1N8Y8THR0d0b59e9G2bVshk8lEly5dxLRp09QOZq6urgKA+P7771Wep6Tien/++Wchk8kUn6GpqakAIMzMzMSVK1fKzDdo0CABQDRs2FC4ubkJT09PYW1tLQAIXV1dERoaWmae4uNnypQpwtPTU8hkMuHm5iY8PDzE0KFDFdO1aNFCABBWVlaiXbt2omPHjsLCwkIAEMbGxopwU1pISIgwMDBQTFd8LBgaGip9rp999pno3LmzACAMDQ2V9n+vXr2UlhkeHq5YZoMGDUSnTp1E06ZNBQAhk8nK/S4rPm4+//xzoaOjIxo1aiS6dOkiHBwcnhvMfvjhB8U+adq0qejcubNwdXVVHM/ffvutEEIzx7EQQvznP/9RrM/Kykp07txZODk5CR0dnUrDHFUvBjPSmMqC2fXr14Wenp4AII4dO6Y07pdffhEAhIuLi9KXbmFhofj0008FAOHg4CBycnKUxnl5eQkAonPnzop/SRaLiYkRq1evVhq2cOFCAUB4eHiImJgYxfDs7Gzx+uuvK5ZVUkXBbMWKFQKAmDZtWrmfxdKlSwUA8corr7xwDcXBTFdXVzRp0kScPHlSMa7kZ1KRr776SgAQHTp0eO60QggRHR2t+LKOjo5WDC/+YdXT0xP29vbi3LlzinEXL14Ujo6OAoB45513lJaXmZmp+LGdO3euSEtLU4y7fPmyaNu2rQAgfvzxR6X5ioOZrq6uGDNmjEhJSSmz3ampqSIwMFBpnBBCPH36VLzxxhsCgJgxY0aZbVSldep5wUxfX1+88cYbilrkcrl4//33FYG7sLBQab7iH8HmzZsrHa+XLl0STk5OQl9fX61g9vjxY8V+Krkv1FE8v4mJidJ609PTFeHL29u7zHybN28WFy5cUBoml8vFjh07FC1u6enpSuOLjx9dXV3RqlUrpc+g5HEcFBQkbt26pTRvQUGB+OOPP4Senp5o3rx5mRbWqKgoxedX3AJZLD8/X4SFhYnjx48rhqlyjdn58+eFoaGhMDIyKtOqu2vXLmFubi50dXXLfPbFx42urq5YtmyZ4h83crlc0QJVXjArKCgQjRo1Enp6emL79u1ltn/37t3i6NGjSsNf5Dj+7rvvFPt+/fr1StuXkpIi/vvf/4qkpKQKl0vVh8GMNKa8YJaWliYOHjyoOD1W+l+keXl5omnTpkJXV7fC0yYTJ04UAERwcLBi2KZNmxSta8nJyc+tLSkpSRgaGgpzc3Nx7969MuOLiopEly5dygTHir7A4+LihEwmE6ampuW2ELVp00YAUDrdUdUaioMZALF169bnbmtp8+fPFwDE+PHjVZo+NTVVsb6Sp2GLf1gBiG3btpWZb9euXQKAMDU1VfpRXrVqVaXrP3/+vJDJZKJ58+ZKw4t/dJo2bar0Q6sOR0fHMi1/JZf9IsGsY8eOZQJCfn6+okWl5PGcmpqqaPU4ceJEmXWV3MeqBrNz584p5ikZdtVRPP+bb75ZZtyFCxcEAGFhYaHWMj/88EMBoEyrWcnjp2TgV4evr68AUKYFfcSIEQKAePnll1VajirBbMKECZW2Rha3bpVeZ/FxM3r06AqXXV4wS0hIUPyjTVVVPY6zs7MVp1dLfq+SduDF/6RxM2fOVPRjZmFhgSFDhuDq1avw9vbG7t27laY9deoUEhMT4enpCQ8Pj3KXN2bMGADA0aNHFcN27twJAHj55ZdhZWX13JoiIiKQl5eHYcOGwcHBocx4HR0djBo1qsx6KuLk5ISePXsiKysLu3btUhoXExODq1evwtbWFv3799dYDRYWFhg7duxzaystIyMDwLOLwFVRcrrieUuyt7cvt45Ro0ahWbNmyMrKQmRkpGL4tm3bAACvvPJKuevr0KEDnJ2dcfv2bdy/f7/M+IkTJz639kOHDuGtt97CyJEj0bdvX/Tu3Ru9e/dGWloasrOzcePGjUrnr4qXX34ZOjrKX6H6+vro2LEjAOD27duK4cePH0dubq6iK5nS+vfvDxcXF7XWX3LfqLpvK1Levmnfvj2MjIyQlpaGlJSUMuPj4+OxcuVKTJkyBQMHDlR85uHh4QCA8+fPl7uutm3bwtPTs9J6rl69iiVLlmDChAno37+/YtnFfxcll52Tk4ODBw8CAN577z3VNvg58vPzERERAV1dXcyYMaPcacr7XirJ399frXU2btwYhoaGuH79eoWfnaZERkYiJSUFdnZ2mD59erWui9Sn9/xJiNTj6uqKJk2aQAiBxMRE3L59G/r6+ujSpQsaNWqkNO3FixcBPOthv3fv3uUuLzU1FQDw4MEDxbArV64AALp3765STcXr+eeffypcz6NHj8qspzI+Pj6IjIxEWFgYpk6dqhgeFhYGAPD29lb64X7RGlxdXaGrq6tSbSU1aNAAAJCVlaXS9CWnK563pNatW5cJJMCzXuRbt26N+Ph4XL9+HS+99BKA/233xx9/jM8//7zcdSYnJwN4tt2lQ6ubm1uFtebn58Pb2xs7duyodJuePHlS6fiqqKhvuyZNmgAAMjMzFcOKg2GHDh0qXF779u1x584dlddfct9kZWXB3Nxc5XlLq2hbGjdujHv37iEzM1PpH0BBQUGYM2cOcnNzK1xmRZ95ZfsTAFasWIEPP/wQcrlcpWXfvHkTBQUFaNiwYZk7Uqvq+vXryM3NhYGBAUaMGFHuNEIIABV/XzxvO0vT1dXF3Llz8dVXX8HT0xO9evXCgAED0KdPH/Tu3RtGRkbqbUQlir8/u3btWu7fMkmLwYw0btGiRUr/yoyMjMS4cePwzjvvwMbGBr6+vopxaWlpAIDHjx/j8ePHlS43JydH8f/p6ekAgIYNG6pUU/F67t27h3v37qm8nspMmTIF8+bNw759+/D06VM0atQIQghFi4GPj49Ga6hqq4i9vT0AqNyrf8npiuctqTh4lMfGxgaAcmtO8XZHR0c/d93qbvfKlSuxY8cONG3aFF9++SX69u2Lpk2bwtDQEADQu3dvREZGoqCg4LnrVldFdRX/0BX/cAP/C7vlBd1ilY0rT8l9c+fOHUVLXVWosy23bt3Cq6++ioKCArz99tvw9fVFixYtYGZmBplMhj/++EMxXp11Ac+eSrFo0SLo6upixYoVGDNmDJycnGBiYgKZTIYPP/wQn332mdKy1f0uUEXxMZufn6/U+lueisJpVf5eV65cCXt7e/z00084fvw4jh8/DgAwNzfH66+/jqVLlyqO7RdRHZ8ZaQ6jMlW7Xr164ffffwcAzJs3T/GlAABmZmYAgOnTp0M8u+axwteRI0cU8xX/iBW3pj1P8XoWL1783PUEBgaqtExra2sMHjwY+fn5itN1kZGRiI+PR8uWLdGlS5dqr0EVPXv2BADExsYqWqYqc+zYMQCAiYlJuT/2lQXopKQkAMoho3i7b9y48dztLnnqVxWhoaEAgMDAQPj5+cHJyUnph+t5AbimFP9Il2xFK62808aVsba2hqurKwDVTr9ryqZNm1BQUICpU6fi66+/RqdOndCgQQPFMzdf5DMv3p/vvvsuFi5cCHd3d5iamla6bHW/C1RRfMza29s/95gtGVpflI6ODubNm4fr16/jzp07CAoKwtSpU5Gbm4uVK1fi7bff1sh6quMzI81hMKMaMW7cOHTv3h1PnjzBN998oxju7u4OAGp3Ztq2bVsAz04LqqKq63me4laxDRs2KP132rRpNVbD83Tr1g3NmjVDYWGhIiBXpKioSDHNhAkTlDqhLXbt2rVyTzMJIXDt2jUAQKtWrRTDq3O7ix/MXBw+S0pJSanwNFNNP7i7+PO4cOFChdMUn/JVh7e3NwDgt99+Q1FRUdWKU1NlnzlQ8bVl1bVsV1dXGBgYIDU1VXH8Pc/z9r+rqyv09fWRkJBQLafBVeHs7Ax/f3+EhYUprmNdu3at0t9eVY/j4u/PqKioSk8ZkzQYzKjGLFy4EACwatUqRctBnz59YG1tjfPnzyu1iD3PuHHjADz7olLli3PkyJEwMDBARESERi8EHz9+PIyNjXHkyBHcu3cPW7ZsAVB+MKuuGp5HV1dX8dl/9tlnlQaATz/9FLGxsdDX16/wQur79++XuYkDAPbs2YO7d+/C1NRU6QL3CRMmAHi23zXZugAAxsbGAP53bV5J//3vfysMK8XzqXra+kUVXyN0/fp1nDp1qsz4Y8eOqXV9WbE33ngDDRs2xOXLl7F48eJKp83Ly8OqVavUXkdplX3mV69eLffY0MSyDxw4UG4wMzY2xtChQwEAX3/9tVrrqWj/m5iYYNiwYZDL5Rr5zF5U8bW0OTk5ePr0qWJ4VY/jXr16wdraGg8ePFBcE0vag8GMasyYMWPg5uaGp0+f4ueffwYAGBkZYfny5QCAyZMnY/v27WV+vC9duoT3339f6VqPcePGoXPnzkhKSsKIESPK/Ev5/PnzinUAgJ2dHebPn4+CggIMGzasTAgUQuD06dP4v//7P6W76Z7HzMwMo0ePhlwux2uvvYbHjx+jU6dO5V74W101qGLOnDkYNWoUsrKyMHDgQISFhaGwsFAxPjk5GfPnz1c8kunzzz9H+/bty12Wnp4e3nzzTaWAFxsbq3hA9pw5c5ROZc6ePRvNmzfH4cOHMX36dCQkJCgtLzMzE5s2bcKCBQvU3q7imyjefvttRdgXQiA4OBhff/11hRdMN2/eHMCzQKTpsFgeCwsLzJo1CwDg5+endLzGxsYiICCgSg+ZtrGxwbp166Crq4svvvgCPj4+Zf4WcnJysGnTJnh4eGDt2rUvtiH432e+evVqpYdnX79+HZMnT4aBgcELL3vlypVKQTUqKgovv/xyhftzyZIl0NfXxx9//IFFixYhOztbMa6goADh4eE4ceKEYljjxo3RoEEDJCUlKS6EL+2TTz6BoaEhPv30U6xcubJM+ElISMD333+PX375pcrbW1JsbCxmz56NqKgopWMyLy8Pn332GYBnd4OXvAmjqsexkZERPvroIwDP/j7DwsKU5n/69Cm+/fbb5173S9VEcz1vUH33vJ7/hRBizZo1ir6pSnYqWdzxKgBhaWkpunTpotSLPwCxd+9epWXdvXtX8TQBAKJVq1bCy8tL0T9P6Z7/CwoKFP0gFdfQtWtX0bFjR9GgQQPF8JI9navS39GOHTsU8wIQX3zxRYXTVqWGko9kehG5ubnCx8dHsY6GDRsKT09P4e7uruj8V19fX3z99dflzl9ez//t2rUT7du3V/Tg36VLl3L7HLty5YpwcXERwLNe793c3ES3bt1Eq1atFA/g7tatm9I8qvTRdObMGUXP7ubm5sLLy0vY2dkJAMLPz0/p8Ukl3bx5U9Gju5OTk+jTp4/o16+f0rpUeSRTeSqqOy0tTXTq1EnxGXTo0EHx2XXu3FlMnTq1yv1K7d69W3HcAxCOjo6iS5cuwt3dXdF/mkwmE3PnzlWar3j6ipT3GRQUFIju3bsrOlF1c3NTPP3B1tZW0Sl0QECA0rJKPpKpImlpaaJ58+YCePaEiPbt2yv+xt3d3cWCBQvK9P9VbP369YpOZk1MTISnp6dwc3NTbH/p/fHyyy8LAMLIyEh07txZ9OvXr8zf2LZt2xRP5TAyMhKdOnUSXbt2VXSmDEC8//77z/3MSiuvH7OYmJgyf5seHh6Kpx4YGBiIiIgIpeW8yHEsl8vF//3f/ynWaW1tLbp06SKcnZ0Vf5Ps+V8aDGakMaoEs7y8PMUP508//aQ0LjIyUvj4+AhHR0fFM+k6dOggXn75ZbFnzx6Rn59fZnmZmZlixYoVwtPTU5iZmQkTExPh6uoqAgICyjxhoNiePXvEuHHjFM/4a9KkifDy8hJvvPGGOHLkiFKnoaoEs7y8PNGoUSPFj9/du3cr/6DUrEFTwazYkSNHhJ+fn3B2dhZGRkbCzMxMuLu7i3nz5okbN25UOF/pZ2XOnz9fNGvWTBgYGAgnJyexcOHCSjuCTU9PFytXrhTdunUT5ubmimdFDhw4UHz99ddlfgRUfXbkv//+K4YMGSLMzMyEqamp6NSpk1i1apWQy+WVhqj9+/eLfv36CXNzc0WwVPdZmeWprO709HTxzjvvKH1uCxYsEBkZGWLSpEkCQJle31WVlpYmvvrqKzFgwABhY2Mj9PX1FY8Rmjdvnjh//nyZeaoSzIrX9eabbwo7Ozuhr68vHBwcxCuvvCIePnxYYQBTJZgJIcTDhw+Fv7+/sLa2VjxHdsGCBSItLa3SZ0wK8exJEjNnzlR8vtbW1sLLy0ssXbq0zHNoMzIyxLx584Szs7Mi0JX3WcTFxYl58+aJNm3aCGNjY2FmZiZat24txo8fL4KCgsTTp09V+sxKKm87MjMzxe+//y4mT54sXF1dhZmZmeJvc86cORU+M7iqx3GxPXv2iFGjRimeS2pvby8GDhwoVq9eXemzgKn6yISogXZ8Iqr1AgMDMXPmTAQEBGj0rlF6pn379rh06RJiYmLQqVMnqcshIonwGjMiIolFRUXh0qVLaNiwoeKOOSKqnxjMiIhqyKJFi8p04XH69GlMmTIFwLPHPFXlJgAiqjsYzIiIasiKFSvg4OAAW1tbdO3aFc7OzujWrRvi4uLQuXNnLFu2TOoSiUhiDGZERDXkiy++QL9+/QA869IlJSUFXl5e+OKLL3D06FFFj/NEVH/x4n8iIiIiLcEWMyIiIiItUfZBePWAXC7Hw4cPlR68S0RERFRdhBDIyMiAnZ0ddHQqbherl8Hs4cOHcHR0lLoMIiIiqmfu3bsHBweHCsfXy2BW/By/e/fuwdzcXOJqiIiIqK5LT0+Ho6Oj0rOEy1Mvg1nx6Utzc3MGMyIiIqoxz7uEihf/ExEREWkJBjMiIiIiLcFgRkRERKQlGMyIiIiItASDGREREZGWYDAjIiIi0hIMZkRERERagsGMiIiISEswmBERERFpCQYzIiIiIi3BYEZERESkJRjMiIiIiLQEgxkRERGRlmAwIyIiItISDGZEREREWoLBjIiIiEhLMJgRERERaQnJg9mxY8cwevRo2NnZQSaTYceOHc+d5+jRo/Dy8oKRkRGaN2+OX375pfoLJSIiIqpmkgezrKwsdOzYET/++KNK09+5cwcjRoxAnz59EBMTg0WLFmHu3LnYunVrNVeq/e7fv4/Dhw/j/v37UpdCRERUa2jT76ee1AUMHz4cw4cPV3n6X375Bc2aNcN3330HAHBzc8OZM2fw9ddfY+LEidVUpfZbs2YNXnvtNcjlcujo6OCHH35AQECA1GURERFptaCgILz55puK38/ffvsNs2bNkqwemRBCSLb2UmQyGbZv345x48ZVOE3fvn3h4eGB77//XjFs+/btmDJlCrKzs6Gvr19mnry8POTl5Snep6enw9HREWlpaTA3N9foNkjh/v37cHJyglwul7oUIiKiWk1XVxdxcXFwcHDQ6HLT09NhYWHx3Owh+alMdSUmJsLGxkZpmI2NDQoLC5GcnFzuPCtWrICFhYXi5ejoWBOl1pgbN24wlBEREWlAUVERbt68Kdn6JT+VWRUymUzpfXGjX+nhxT744AMsWLBA8b64xayucHV1hY6OjlI409XVRWxsLOzt7SWsjIiISDsJIbBlyxa8/PLLKHnyUFdXFy1btpSsrloXzJo2bYrExESlYUlJSdDT04OVlVW58xgaGsLQ0LAmypOEg4MDfvjhB/znP/8B8Oyg+vXXX9GqVSuJKyMiItI+Qgj8/fffuHv3LkaPHo0///wTcrlc8fup6dOY6qh1pzJ79OiBgwcPKg07cOAAOnfuXO71ZfVFyQv9Y2NjJb1wkYiISFsJIfDXX38hMjISALBo0SLcvXsXhw8fRlxcnOS/n5K3mGVmZiqdy71z5w7OnTsHS0tLNGvWDB988AEePHiA4OBgAMCcOXPw448/YsGCBXj11Vdx6tQprFmzBmFhYVJtgtbh6UsiIqKyikPZyZMnATzrGaJr164AIGkrWUmSB7MzZ85gwIABivfF14IFBAQgMDAQCQkJiI+PV4x3cXFBREQE3nrrLfz000+ws7PDqlWr6nVXGURERFQ5IQQOHjyIU6dOAVAOZdpEq7rLqCmq3rJam2RlZcHMzAzAs1ZIU1NTiSsiIiLSDkIIHDhwAP/88w8AYMSIEejSpUuN1qBq9pC8xYyIiIiougghsH//fvz7778AgJEjR6Jz584SV1UxBjMiIiKqk4QQ2LdvH06fPg0AGDVqFLy8vCSuqnIMZkRERFTnlA5lo0ePhqenp8RVPR+DGREREdUpQgjs3bsXUVFRAGpPKAMYzIiIiKgOEUIgIiICZ86cAQCMGTMGHh4eElelOgYzIiIiqhOEENizZw+io6MBAGPHjkWnTp2kLUpNta7nfyIiIqLS6kIoA9hiRkRERLWcEAJ//vknzp49CwAYN24cOnbsKHFVVcNgRkRERLWWEAK7d+9GTEwMZDIZxo0bhw4dOkhdVpUxmBEREVGtJITArl27cO7cOchkMowfPx7t27eXuqwXwmBGREREtY5cLsfu3bvrVCgDGMyIiIiolpHL5di1axfOnz8PmUyGCRMmoF27dlKXpREMZkRERFRrlA5lEydORNu2baUuS2MYzIiIiKhWkMvl2LlzJy5cuFAnQxnAYEZERES1gFwux44dO3Dx4kXo6Ohg4sSJcHd3l7osjWMwIyIiIq1WOpRNmjQJbm5uUpdVLRjMiIiISGvJ5XJs374dly5dqvOhDGAwIyIiIi0ll8uxbds2XL58GTo6Opg8eTLatGkjdVnVisGMiIiItE5RURG2bduG2NhY6OjoYMqUKWjdurXUZVU7PsSciIiItEp9DWUAW8yIiIhIixQVFWHr1q24cuUKdHV1MWXKFLRq1UrqsmoMgxkRERFphaKiImzZsgVXr16Frq4uvL294erqKnVZNYqnMomIiEhyDGXPsMWMiIiIJFVUVITNmzfj2rVr0NXVxdSpU9GyZUupy5IEgxkRERFJprCwEJs3b8b169frfSgDGMyIiIhIIiVDmZ6eHqZOnYoWLVpIXZakGMyIiIioxhUWFmLTpk24ceMG9PT0MG3aNDRv3lzqsiTHi/+JiIioRjGUVYwtZkRERFRjCgsLER4ejps3b0JPTw8+Pj5wcXGRuiytwWBGRERENaKwsBAbN27ErVu3oK+vDx8fHzg7O0tdllZhMCMiIqJqV1BQgPDwcIay52AwIyIiompVUFCAjRs34vbt29DX18f06dPh5OQkdVlaiRf/ExERUbVhKFMPW8yIiIioWhQUFCAsLAx37tyBgYEBpk+fjmbNmkldllZjMCMiIiKNy8/PR1hYGOLi4hjK1MBgRkRERBpVOpT5+vrC0dFR6rJqBQYzIiIi0pj8/Hxs2LABd+/eZSirAgYzIiIi0oj8/HyEhoYiPj4ehoaG8PX1hYODg9Rl1SoMZkRERPTC8vLysGHDBkUo8/Pzg729vdRl1ToMZkRERPRC8vLyEBoainv37jGUvSAGMyIiIqqykqHMyMgIfn5+sLOzk7qsWovBjIiIiKokLy8PISEhuH//PkOZhjCYERERkdpyc3MRGhqqCGX+/v6wtbWVuqxaj8GMiIiI1JKbm4uQkBA8ePAAxsbG8PPzYyjTEAYzIiIiUlnpUObv74+mTZtKXVadwWBGREREKsnJyUFISAgePnzIUFZNGMyIiIjouXJycrB+/XokJCTAxMQE/v7+sLGxkbqsOkdH6gKIiIhIuzGU1Ry2mBEREVGFcnJyEBwcjMTERJiYmCAgIABNmjSRuqw6i8GMiIiIypWdnY3169cjMTERpqam8Pf3ZyirZgxmREREVEZ2djaCg4Px6NEjmJqaIiAgAI0bN5a6rDqP15gRERGREoYy6bDFjIiIiBSysrIQHByMpKQkmJmZISAgANbW1lKXVW+wxYyIiIgAMJRpA7aYEREREbKyshAUFITHjx8zlEmIwYyIiKiey8zMRHBwMB4/fowGDRogICAAVlZWUpdVLzGYERER1WOZmZkICgpCcnIyQ5kWYDAjIiKqpzIyMhAcHIzk5GSYm5sjICAAlpaWUpdVrzGYERER1UMZGRkICgpCSkoKQ5kWYTAjIiKqZ0qGMgsLCwQEBKBRo0ZSl0VgMCMiIqpX0tPTERQUhCdPnjCUaSH2Y0ZERFRPMJRpP7aYERER1QMlQ1nDhg0REBCAhg0bSl0WlcJgRkREVMelpaUhKCgIT58+ZSjTcgxmREREdVjpUDZjxgxYWFhIXRZVgMGMiIiojkpNTUVQUBBSU1PRqFEjBAQEMJRpOV78T0REVAcxlNVObDEjIiKqY1JTUxEYGIi0tDRYWloiICAA5ubmUpdFKmAwIyIiqkOePn2KoKAghrJaisGMiIiojigZyqysrODv789QVsswmBEREdUBT548QVBQENLT02FlZYWAgAA0aNBA6rJITQxmREREtVzJUGZtbQ1/f3+GslqKwYyIiKgWe/LkCQIDA5GRkQFra2sEBATAzMxM6rKoihjMiIiIaqmUlBQEBQUhIyMDjRs3hr+/P0NZLcd+zIiIiGohhrK6iS1mREREtUxycjKCgoKQmZmJxo0bIyAgAKamplKXRRrAYEZERFSLlAxlTZo0gb+/P0NZHcJgRkREVEs8fvwYwcHBDGV1GIMZERFRLfD48WMEBQUhKysLNjY28Pf3h4mJidRlkYYxmBEREWm5pKQkBAcHIysrC02bNoWfnx9DWR3FYEZERKTFkpKSEBQUhOzsbIayeoDBjIiISEs9evQIwcHBilDm7+8PY2NjqcuiasRgRkREpIVKhjJbW1v4+fkxlNUDDGZERERaJjExEcHBwcjJyYGdnR18fX0ZyuoJBjMiIiItUjqU+fn5wcjISOqyqIYwmBEREWmJhIQErF+/Hjk5ObC3t4evry9DWT3DYEZERKQFEhISEBwcjNzcXIayekwrHmK+evVquLi4wMjICF5eXjh+/Hil04eGhqJjx44wMTGBra0tZs6ciZSUlBqqloiISLMePnyoCGUODg4MZfWY5MEsPDwc8+fPx+LFixETE4M+ffpg+PDhiI+PL3f6EydOwN/fH7NmzcLly5exefNmREVF4ZVXXqnhyomIiF7cw4cPsX79eoYyAqAFweybb77BrFmz8Morr8DNzQ3fffcdHB0d8fPPP5c7/T///ANnZ2fMnTsXLi4u6N27N2bPno0zZ87UcOVEREQv5sGDB4pQ5ujoCF9fXxgaGkpdFklI0mCWn5+P6OhoDB06VGn40KFDcfLkyXLn6dmzJ+7fv4+IiAgIIfDo0SNs2bIFI0eOrHA9eXl5SE9PV3oRERFJqXQomz59OkMZSRvMkpOTUVRUBBsbG6XhNjY2SExMLHeenj17IjQ0FN7e3jAwMEDTpk3RsGFD/PDDDxWuZ8WKFbCwsFC8HB0dNbodRERE6rh//z7Wr1+PvLw8NGvWjKGMFCQ/lQkAMplM6b0QosywYrGxsZg7dy4+/vhjREdHY9++fbhz5w7mzJlT4fI/+OADpKWlKV737t3TaP1ERESqun//PkJCQpCXlwcnJyeGMlIiaXcZ1tbW0NXVLdM6lpSUVKYVrdiKFSvQq1cvvPvuuwCADh06wNTUFH369MGnn34KW1vbMvMYGhryoCciIsndu3cPISEhyM/Ph5OTE3x8fGBgYCB1WaRFJG0xMzAwgJeXFw4ePKg0/ODBg+jZs2e582RnZ0NHR7lsXV1dAM9a2oiIiLRRyVDm7OzMUEblkvxU5oIFC/DHH39g7dq1uHLlCt566y3Ex8crTk1+8MEH8Pf3V0w/evRobNu2DT///DNu376NyMhIzJ07F127doWdnZ1Um0FERFSh+Ph4hjJSieQ9/3t7eyMlJQXLly9HQkIC2rVrh4iICDg5OQF41hNyyT7NZsyYgYyMDPz44494++230bBhQwwcOBBffPGFVJtARERUoeJQVlBQABcXF0ybNg36+vpSl0VaSibq4fm/9PR0WFhYIC0tDebm5lKXoxFZWVkwMzMDAGRmZsLU1FTiioiI6O7duwgNDUVBQQGaN2+OqVOnMpTVU6pmD8lbzIiIiOqiuLg4bNiwgaGM1MJgRkREpGElQ1mLFi3g7e3NUEYqYTAjIiLSoDt37iAsLAwFBQVo2bIlvL29oafHn1tSDY8UIiIiDblz5w42bNiAwsJChjKqEh4tREREGnD79m2EhYWhsLAQrq6umDJlCkMZqU3yfsyIiIhqO4Yy0hQeNURERC/g1q1b2LhxIwoLC9GqVStMnjyZoYyqjEcOERFRFd28eRMbN25EUVERWrdujUmTJjGU0Qvh0UNERFQFpUPZ5MmTFc9uJqoqBjMiIiI13bhxA+Hh4SgqKkKbNm0wadIkhjLSCAYzIiIiNVy/fh2bNm1CUVER3NzcMHHiRIYy0hjelUlERKQihjKqbmwxIyIiUsG1a9ewadMmyOVyuLu7Y8KECQxlpHEMZkRERM9x9epVbN68GXK5HG3btsX48eMZyqhaMJgRERFVomQoa9euHcaPHw8dHV4JRNWDwYyIiKgCV65cwZYtWxjKqMYwmBEREZUjNjYWW7duhVwuR/v27TFu3DiGMqp2DGZERESlxMbGYsuWLRBCoEOHDhg7dixDGdUIBjMiIqISLl++jK1btzKUkSQYzIiIiP6/S5cuYdu2bRBCoGPHjhgzZgxDGdUoBjMiIiIoh7JOnTph9OjRDGVU4xjMiIio3rt48SK2b9+uCGVjxoyBTCaTuiyqhxjMiIioXrtw4QJ27NgBIQQ8PDwwevRohjKSDNtoiYio3mIoI23DFjMiIqqXzp8/jx07dgAAPD09MWrUKIYykhyDGRER1Tvnzp3Dzp07AQBeXl4YOXIkQxlpBQYzIiKqV0qGss6dO2PEiBEMZaQ1GMyIiKjeiImJwa5duwAwlJF2YjAjIqJ64ezZs9i9ezcAoEuXLhg+fDhDGWkdBjMiIqrzoqOj8eeffwIAunbtipdeeomhjLQSgxkREdVpJUNZt27dMGzYMIYy0loMZkREVGedOXMGe/bsAcBQRrUDgxkREdVJUVFRiIiIAAB0794dQ4cOZSgjrcdgRkREdc7p06exd+9eAECPHj0wZMgQhjKqFRjMiIioTikZynr27InBgwczlFGtwWBGRER1xr///ot9+/YBAHr16oVBgwYxlFGtwmBGRER1wj///IP9+/cDAHr37o2BAwcylFGtw2BGRES13qlTp3DgwAEADGVUuzGYERFRrVYylPXp0wcDBgxgKKNai8GMiIhqrZMnT+LgwYMAgL59+6J///4MZVSrMZgREVGtFBkZib/++gsA0K9fP/Tv31/agog0gMGMiIhqnRMnTuDvv/8GwFBGdQuDGRER1SrHjx/HoUOHAAD9+/dHv379JK6ISHMYzIiIqNY4duwYDh8+DAAYMGAA+vbtK3FFRJrFYEZERLVCyVA2cOBA9OnTR+KKiDSPwYyIiLTe0aNHceTIEQAMZVS3MZgREZFWO3LkCI4ePQoAGDRoEHr37i1xRUTVh8GMiIi0khACR44cwbFjxwAAgwcPRq9evSSuiqh6MZgREZHWKR3KhgwZgp49e0pcFVH1YzAjIiKtIoTA4cOHcfz4cQDA0KFD0aNHD4mrIqoZDGZERKQ1hBA4dOgQTpw4AYChjOofBjMiItIKQgj8/fffiIyMBAAMGzYM3bt3l7gqoprFYEZERJITQuCvv/7CyZMnAQAvvfQSunXrJnFVRDWPwYyIiCRVOpQNHz4cXbt2lbgqImkwmBERkWSEEDh48CBOnToFgKGMiMGMiIgkIYTAgQMH8M8//wAARowYgS5dukhcFZG0GMyIiKjGCSGwf/9+/PvvvwCAkSNHonPnzhJXRSQ9BjMiIqpRQgjs27cPp0+fBgCMGjUKXl5eEldFpB0YzIiIqMaUDmWjR4+Gp6enxFURaQ8GMyIiqhFCCOzduxdRUVEAGMqIysNgRkRE1U4IgYiICJw5cwYAMGbMGHh4eEhcFZH2YTAjIqJqJYTAnj17EB0dDQAYO3YsOnXqJG1RRFpKR+oCiIio7mIoI1IPW8yIiKhaCCHw559/4uzZswCAcePGoWPHjhJXRaTdGMyIiEjjhBDYvXs3YmJiIJPJMG7cOHTo0EHqsoi0HoMZERFplBACu3btwrlz5yCTyTB+/Hi0b99e6rKIagUGMyIi0hi5XI7du3czlBFVEYMZERFphFwux65du3D+/HnIZDJMmDAB7dq1k7osolqlSndlXr16FdOmTYOtrS0MDAwUF3YuW7YMhw8f1miBRESk/UqHsokTJzKUEVWB2sHs3Llz6NKlC44ePYr+/fujqKhIMS4zMxO//PKLRgskIiLtJpfLsXPnTqVQ1rZtW6nLIqqV1A5mCxcuRIcOHXDz5k2sX78eQgjFuK5duyoetUFERHWfXC7Hjh07cOHCBejo6GDSpEkMZUQvQO1rzCIjIxESEgITExOl1jIAsLGxQWJiosaKIyIi7VUcyi5evKgIZW5ublKXRVSrqR3MhBAwMDAod9zTp09haGj4wkUREZF2k8vl2L59Oy5dusRQRqRBap/K7NChA7Zv317uuH379sHLy+uFiyIiIu0ll8uxbds2RSibPHkyQxmRhqjdYjZv3jz4+PjA1NQUfn5+AID4+HgcOnQIa9euxZYtWzReJBERaYeioiJs27YNsbGx0NHRwZQpU9C6dWupyyKqM9QOZt7e3rh16xaWLl2KVatWAQAmTpwIPT09LFu2DKNHj9Z4kUREJD2GMqLqJxMlb6tUw/3797F//348evQI1tbWGDZsGJycnDRdX7VIT0+HhYUF0tLSYG5uLnU5GpGVlQUzMzMAz7otMTU1lbgiIqpLioqKsHXrVly5cgW6urqYMmUKWrVqJXVZRLWGqtlD7RazY8eOwdPTEw4ODpg1a5bSuMzMTJw9exZ9+/ZVv2IiItJKRUVF2LJlC65evQpdXV14e3vD1dVV6rKI6iS1L/4fMGAAYmNjyx137do1DBgw4IWLIiIi7cBQRlSzqtRdRkUKCgqgo1OlpzwREZGWKSoqwubNm3Ht2jXo6upi6tSpaNmypdRlEdVpKgWz9PR0pKamKt4nJiYiPj5eaZqcnBwEBQWhadOmGi2QiIhqXmFhITZv3ozr168zlBHVIJWC2bfffovly5cDAGQyGcaPH1/udEIILFq0SHPVERFRjSsZyvT09DB16lS0aNFC6rKI6gWVgtnQoUNhZmYGIQTee+89vPnmm2jWrJnSNIaGhmjfvj369etXLYUSEVH1KywsxKZNm3Djxg3o6elh2rRpaN68udRlEdUbKgWzHj16oEePHgCedcvw6quvws7OrloLIyKimsVQRiQ9tS/+X7JkSXXUQUREEiosLER4eDhu3rwJPT09+Pj4wMXFReqyiOodtYMZ8OxOnb179+LKlSvIyclRGieTyfDRRx9ppDgiIqp+hYWF2LhxI27dugV9fX34+PjA2dlZ6rKI6iW1g1lKSgr69OmDq1evQiaTKbrPkMlkimkYzIiIaoeCggKEh4czlBFpCbU7HVu8eDGMjIxw9+5dCCHw77//4saNG1iwYAFatWpVphsNVaxevRouLi4wMjKCl5cXjh8/Xun0eXl5WLx4MZycnGBoaIgWLVpg7dq1aq+XiKg+KygoUGopmz59OkMZkcTUbjH7+++/sWTJEsXF/zo6OmjRogW++uor5Obm4p133kFYWJjKywsPD8f8+fOxevVq9OrVC7/++iuGDx+O2NjYMnd+FpsyZQoePXqENWvWoGXLlkhKSkJhYaG6m0JEVG8Vh7Lbt28rQllted4xUV2mdjC7f/8+nJ2doaurCx0dHWRlZSnGjR49Gj4+Pmot75tvvsGsWbPwyiuvAAC+++477N+/Hz///DNWrFhRZvp9+/bh6NGjuH37NiwtLQGA/8IjIlJDQUEBwsLCcOfOHRgYGGD69OkV/kOYiGqW2qcyra2tkZaWBgCws7PDpUuXFOOePHmiVstVfn4+oqOjMXToUKXhQ4cOxcmTJ8udZ9euXejcuTO+/PJL2Nvbo1WrVnjnnXfK3IRQUl5eHtLT05VeRET1UX5+PjZs2MBQRqSl1G4x8/LywuXLlzFy5EiMGDECy5cvh7m5OQwMDLBo0SJ0795d5WUlJyejqKgINjY2SsNtbGyQmJhY7jy3b9/GiRMnYGRkhO3btyM5ORmvv/46njx5UuF1ZitWrMCyZctU30giojooPz8fYWFhiIuLg4GBAXx9feHo6Ch1WURUgtotZm+88QYsLCwAAJ988gmaNm0Kf39/TJ06Fbq6uvj+++/VLqLkHZ3As0c7lR5WTC6XQyaTITQ0FF27dsWIESPwzTffIDAwsMJWsw8++ABpaWmK171799SukYioNituKWMoI9JuareYDR48GIMHDwYANG7cGDExMbh06RJkMhnatGkDPT3VF2ltbQ1dXd0yrWNJSUllWtGK2drawt7eXhEOAcDNzQ1CCNy/fx+urq5l5jE0NIShoaHKdRER1SX5+fkIDQ1FfHw8DA0N4evrCwcHB6nLIqJyqN1iVppMJkP79u3Rrl076OrqIiQkROV5DQwM4OXlhYMHDyoNP3jwIHr27FnuPL169cLDhw+RmZmpGHb9+nXo6Ojwi4aIqJS8vDylUObn58fvSiIt9sLBrFh4eDjatm2LgIAAteZbsGAB/vjjD6xduxZXrlzBW2+9hfj4eMyZMwfAs9OQ/v7+iul9fHxgZWWFmTNnIjY2FseOHcO7776Ll19+GcbGxpraHCKiWq+8UGZvby91WURUCZWD2cqVK+Hi4gITExN4eHhg3759AICTJ0+iU6dO8PHxwdOnT/Hjjz+qVYC3tze+++47LF++HJ06dcKxY8cQERGh6E8nISFBqdNaMzMzHDx4EKmpqejcuTOmT5+O0aNHY9WqVWqtl4ioLisOZffu3YORkRH8/f0ZyohqAZkofqZSJX766Se8+eabsLCwQKtWrXDv3j08efIEP/zwA/7zn/9AX18f7733Ht555x2YmprWRN0vJD09HRYWFkhLS4O5ubnU5WhEVlYWzMzMAACZmZm1Yj8QUfXIy8tDSEgI7t+/DyMjI/j5+Sk6BSciaaiaPVS6Un/t2rXo3bs39uzZgwYNGqCoqAj/93//hzlz5sDZ2Rn79+9Hy5YtNVY8ERFVTW5uLkJDQxWhzN/fH7a2tlKXRUQqUulU5rVr17BgwQI0aNAAAKCrq4sPP/wQQgh88sknDGVERFogNzdX0VJmbGzMUEZUC6nUYpadnV2mGbz4WoXyuqcgIqKaVRzKHjx4oAhlTZs2lbosIlKTyp2OVdThqzr9lhERkebl5OQgJCQEDx8+ZCgjquVUTlVvv/02GjZsqHhffM/A/PnzlTp7lclk2Llzp+YqJCKiCuXk5GD9+vVISEiAiYkJ/P39K+ygm4i0n0rBrFmzZrh3716ZRxk5OTkpdWUBVNyyRkREmsVQRlT3qBTM4uLiqrkMIiJSR05ODoKDg5GYmAgTExMEBASgSZMmUpdFRC+IF4gREdUy2dnZWL9+PRITE2Fqagp/f3+GMqI6gsGMiKgWyc7ORnBwMB49egRTU1MEBASgcePGUpdFRBqisWdlEhFR9WIoI6r72GJGRFQLZGVlITg4GElJSTAzM0NAQACsra2lLouINIwtZkREWo6hjKj+YIsZEZEWy8rKQlBQEB4/fsxQRlQPVDmYpaWl4Z9//kFycjJGjBiBRo0aabIuIqJ6LzMzE8HBwXj8+DEaNGiAgIAAWFlZSV0WEVWjKp3K/OSTT2BnZ4fhw4fD398fd+7cAQAMGjQIK1eu1GiBRET1UWZmpqKljKGMqP5QO5itXr0ay5Ytw6xZs7Bnzx7Fo5kAYNSoUdizZ49GCyQiqm8yMjIQFBSE5ORkmJubY8aMGQxlRPWE2qcyf/zxRyxYsABffvklioqKlMa5urrixo0bGiuOiKi+KQ5lKSkpMDc3R0BAACwtLaUui4hqiNrB7Pbt2xg2bFi54xo0aIDU1NQXrYmIqF4qGcosLCwQEBDA63eJ6hm1g5mFhQUePXpU7ri4uDg+FoSIqArS09MRFBSEJ0+eMJQR1WNqX2M2aNAgfPnll8jKylIMk8lkKCwsxM8//1xhaxoREZWPoYyIiqndYrZ8+XJ06dIF7u7uGD9+PGQyGX788UfExMQgPj4emzZtqo46iYjqpJKhrGHDhggICEDDhg2lLouIJKJ2i1nLli0RGRkJNzc3rF69GkIIBAcHw9raGsePH0ezZs2qo04iojonLS0NgYGBDGVEpFClDmbd3d2xb98+5OXlISUlBY0aNYKxsbGmayMiqrPS0tIQFBSEp0+fomHDhpgxYwYsLCykLouIJKZ2i9mff/4JuVwOADA0NISdnR1DGRGRGlJTUxEYGIinT5+iUaNGDGVEpKB2MBszZgzs7e3x/vvv48qVK9VRExFRnZWamoqgoCCkpqaiUaNGCAgIYCgjIgW1g9mePXvQt29frFq1Cu3atUOPHj3w+++/IyMjozrqIyKqM4pbylJTU2FpacmWMiIqQ+1gNnz4cISHhyMhIQE//PAD5HI5Zs+ejaZNm8LPzw+HDh2qjjqJiGq1p0+fIjAwEGlpabC0tERAQADMzc2lLouItIxMlHzYZRVduXIF69atU/RYXVhYqInaqk16ejosLCyQlpZWZ74Ys7KyYGZmBuDZw49NTU0lroiIij19+hRBQUFIS0uDlZUV/P3968x3DxGpRtXsUaW7MksSQuDevXu4d+8e0tPToYGcR0RUZzx58gRBQUFIT0+HlZUVAgIC0KBBA6nLIiItpfapzGI3b97Ehx9+CCcnJwwfPhwnTpzAggULcO3aNU3WR0RUa5UMZdbW1gxlRPRcareYrVu3DuvWrUNkZCQMDAwwZswYzJw5E0OHDoWOTpVzHhFRnfLkyRMEBgYiIyNDEcqKLzcgIqqI2sFs1qxZ8PDwwPfff4/p06fzeW5ERKWkpKQgKCgIGRkZaNy4Mfz9/RnKiEglagezc+fOoUOHDtVRCxFRrcdQRkQvQu1gxlBGRFS+5ORkBAUFITMzE40bN0ZAQADvkCYitagUzJYvX45XXnkFdnZ2WL58eaXTymQyfPTRRxopjoiotigZypo0aQJ/f3+GMiJSm0r9mOno6OCff/5B165dn3uBv0wmQ1FRkcYKrA7sx4yINOnx48cIDg5mKCOiCmm0H7Pih5aX/n8iovru8ePHCAoKQlZWFmxsbODv7w8TExOpyyKiWuqFO5glIqqvkpKSEBwcjKysLMVj6RjKiOhFqN3xmK6uLk6fPl3uuOjoaOjq6r5wUURE2i4pKUnRUsZQRkSaonaLWWWXpMnlcshkshcqiIhI2z169AjBwcHIzs5G06ZN4e/vD2NjY6nLIqI6oEqnMisKX9HR0bCwsHihgoiItFnJUGZraws/Pz+GMiLSGJWC2ffff4/vv/8ewLNQNm7cOBgaGipNk5OTg6SkJEyaNEnzVRIRaYHExEQEBwcjJycHdnZ28PX1ZSgjIo1SKZg1adIEbdu2BQDExcWhefPmaNiwodI0hoaGaN++PebNm6fxIomIpFY6lPn5+cHIyEjqsoiojlGpH7OSBgwYgJ9//hlt2rSprpqqHfsxIyJ1JCQkYP369cjJyYG9vT18fX0ZyohILRrtx6ykw4cPv1BhRES1SUJCAoKDg5Gbm8tQRkTVTqVgFh8fD1tbW+jr6yM+Pv650zdr1uyFCyMiktrDhw+xfv165ObmwsHBAdOnT2coI6JqpVIwc3FxwalTp9C1a1c4Ozs/t0sMbX8kExHR85QOZb6+vmVueiIi0jSVgtnatWvRokULxf+zrzIiqssePHiAkJAQ5ObmwtHREdOnT2coI6IaofbF/3UBL/4nooo8ePAA69evR15eHkMZEWmMqtlD7UcylSc3NxdXr17lKUwiqtXu37+vCGXNmjVjKCOiGqd2MPvhhx/wySefKN5HR0fD0dERbdu2RatWrXDv3j2NFkhEVBPu37+PkJAQ5OXlwcnJiaGMiCShdjD7448/lDqXff/992FpaYlvv/0WQgh8+umnmqyPiKja3bt3T9FS5uTkBB8fHxgYGEhdFhHVQ2r3YxYfH6/oXDYjIwPHjh3Dxo0bMWHCBDRq1Agff/yxxoskIqou9+7dQ0hICPLz8+Hs7Ixp06YxlBGRZNQOZnl5edDX1wcAnDp1CnK5HIMHDwYAODs7IzExUbMVEhFVk/j4eISGhipCmY+Pj+L7jYhICmqfymzWrBmOHz8OANi5cyc6deqkuLvg8ePHdeYuRyKq2+Lj4xUtZS4uLgxlRKQV1G4x8/X1xbJly7Bjxw6cP38eX3/9tWLcmTNn0KpVK40WSESkaXfv3kVoaCgKCgrQvHlzTJ06laGMiLSC2sFs8eLF0NPTw8mTJzF+/Hi8+eabinGXLl3CxIkTNVogEZEmxcXFYcOGDQxlRKSV2MFsHTn1yg5miZ6vZChr0aIFvL29GcqIqEaomj3UbjErlpGRgVOnTiElJQXW1tbo3r07GjRoUNXFERFVqzt37iAsLAwFBQVo2bIlvL29oadX5a9AIqJqUaVvpa+//hrLli1DdnY2hBCQyWQwMTHBsmXLsGDBAk3XSET0Qu7cuYMNGzagsLCQoYyItJra30zBwcF47733MHz4cMyYMQN2dnZ4+PAhgoKC8O6776Jx48bw8/OrjlqJiNR2+/ZthIWFobCwEK6urpgyZQpDGRFpLbWvMfPw8EDbtm0REhJSZpyvry9iY2Nx9uxZjRVYHXiNGVH9wFBGRNqi2h5ifvXqVfj6+pY7ztfXF1euXFF3kUREGnfr1i1FKGvVqhVDGRHVCmp/SxkbG+PJkyfljnvy5AmMjY1fuCgiohdx8+ZNbNy4EUVFRWjdujUmTZrEUEZEtYLaLWZ9+vTB0qVL8fDhQ6XhiYmJWL58Ofr27aux4oiI1FU6lE2ePJmhjIhqDbW/rT7//HP06NEDLVu2xKBBg2Bra4uEhAQcOnQI+vr62LZtW3XUSUT0XDdu3EB4eDiKiorQpk0bTJo0Cbq6ulKXRUSkMrVbzNq2bYuoqCiMHTsWUVFRWLduHaKiojBu3DicPn0a7u7u1VEnEVGlrl+/rghlbm5uDGVEVCup1WJWVFSEx48fw9nZGWFhYdVVExGRWq5fv45NmzYpQtnEiRMZyoioVlKpxUwIgQ8++AANGzaEvb09zM3NMW3aNGRkZFR3fURElbp27Zqipczd3Z2hjIhqNZVazFatWoUvvvgCzZs3h5eXF27evInw8HAYGBggKCioumskIirX1atXsXnzZsjlcrRt2xbjx49nKCOiWk2lFrN169ZhxIgRuHr1KsLDwxEdHY33338f4eHhyM3Nre4aiYjKKBnK2rVrhwkTJjCUEVGtp1Iwu379OubMmaN0y/ncuXORn5+PO3fuVFtxRETluXLlilIoGz9+PHR01L6XiYhI66h0KjM3NxdNmjRRGlb8ni1mRFSTYmNjsXXrVsjlcrRv3x7jxo1jKCOiOkPluzJlMll11kFE9FyxsbHYsmULhBDo0KEDxo4dy1BGRHWKysHMx8en3McteXt7w8jISPFeJpPh/PnzmqmOiOj/u3z5MrZu3cpQRkR1mkrBrG/fvuW2mPXr10/jBRERlXbp0iVs27YNQgh07NgRY8aMYSgjojpJpWB25MiRai6DiKh8JUNZp06dMHr0aIYyIqqz+GRfItJaFy9exPbt2xWhbMyYMbzelYjqNAYzItJKFy5cwI4dOyCEgIeHB0aPHs1QRkR1Hs8HEJHWYSgjovqKLWZEpFXOnz+PHTt2AAA8PT0xatQohjIiqjcYzIhIa5w7dw47d+4EAHh5eWHkyJEMZURUrzCYEZFWKBnKOnfujBEjRjCUEVG9U+VgdvXqVRw9ehTJycmYNWsWmjZtiocPH6JRo0bldkRLRFSRmJgY7Nq1CwBDGRHVb2oHs6KiIrz22msIDAyEEAIymQzDhw9H06ZNMXv2bHh4eGD58uXVUSsR1UFnz57F7t27AQBdunTB8OHDGcqIqN5S+67Mzz77DBs2bMBXX32FS5cuQQihGDd8+HDs27dPowUSUd0VHR2tCGVdu3ZlKCOiek/tFrPAwEB89NFHWLBgAYqKipTGubi44M6dOxorjojqrujoaPz5558AgG7dumHYsGEMZURU76ndYvbgwQP06NGj3HFGRkbIyMhQu4jVq1fDxcUFRkZG8PLywvHjx1WaLzIyEnp6eujUqZPa6yQi6Zw5c4ahjIioHGoHsyZNmuD27dvljrt27RocHBzUWl54eDjmz5+PxYsXIyYmBn369MHw4cMRHx9f6XxpaWnw9/fHoEGD1FofEUkrKioKe/bsAQB0796doYyIqAS1g9mIESPw2Wef4cGDB4phMpkMaWlpWLVqFUaPHq3W8r755hvMmjULr7zyCtzc3PDdd9/B0dERP//8c6XzzZ49Gz4+PhW23hGR9jl9+jQiIiIAAD169MDQoUMZyoiISlA7mC1fvhyFhYVwd3fHxIkTIZPJsGjRIrRr1w65ubn46KOPVF5Wfn4+oqOjMXToUKXhQ4cOxcmTJyucb926dbh16xaWLFmi0nry8vKQnp6u9CKimnX69Gns3bsXANCzZ08MGTKEoYyIqBS1g5mNjQ2ioqIwbdo0REdHQ1dXF+fPn8fw4cNx8uRJWFpaqrys5ORkFBUVwcbGpsw6EhMTy53nxo0bWLhwIUJDQ6Gnp9q9CytWrICFhYXi5ejoqHKNRPTi/v33X0Uo69WrFwYPHsxQRkRUjip1MGtjY4NffvlFY0WU/oIu7h+ttKKiIvj4+GDZsmVo1aqVysv/4IMPsGDBAsX79PR0hjOiGvLPP/9g//79AIDevXtj4MCBDGVERBWQ9JFM1tbW0NXVLdM6lpSUVKYVDQAyMjJw5swZxMTE4I033gAAyOVyCCGgp6eHAwcOYODAgWXmMzQ0hKGhYfVsBBFV6NSpUzhw4AAAhjIiIlWoHcxefvnlSsfLZDKsWbNGpWUZGBjAy8sLBw8exPjx4xXDDx48iLFjx5aZ3tzcHBcvXlQatnr1ahw6dAhbtmyBi4uLSusloupXMpT16dMHAwYMYCgjInoOtYPZoUOHyny5pqSkIDMzEw0bNkTDhg3VWt6CBQvg5+eHzp07o0ePHvjtt98QHx+POXPmAHh2GvLBgwcIDg6Gjo4O2rVrpzR/kyZNYGRkVGY4EUnn5MmTOHjwIACgb9++6N+/P0MZEZEK1A5mcXFx5Q4/dOgQXn/9dWzevFmt5Xl7eyMlJQXLly9HQkIC2rVrh4iICDg5OQEAEhISntunGRFpj8jISPz1118AgH79+qF///7SFkREVIvIRMmHXb6gH3/8Edu2bcOhQ4c0tchqkZ6eDgsLC6SlpcHc3FzqcjQiKysLZmZmAIDMzEyYmppKXBHVRydOnMDff/8NgKGMiKgkVbOH2t1lVMbd3R2nT5/W5CKJqJY4fvy4IpT179+foYyIqAo0elfm0aNHYW1trclFElEtcOzYMRw+fBgAMGDAAPTt21fiioiIaie1g9ny5cvLDMvLy8OFCxewd+9evPvuuxopjIhqh5KhbODAgejTp4/EFRER1V5qB7OlS5eWGWZoaAhnZ2csX76cwYyoHjl69CiOHDkCgKGMiEgT1A5mcrm8OuogolrmyJEjOHr0KABg0KBB6N27t8QVERHVfmpd/J+TkwMfHx+cOHGiuuohIi0nhMDhw4cVoWzw4MEMZUREGqJWMDM2NsbOnTvZakZUTwkhcOTIERw7dgwAMGTIEPTq1UviqoiI6g61u8vo1KkTLl26VB21EJEWK24pKw5lQ4cORc+ePSWuioioblE7mK1cuRJffvml4jQGEdV9QggcOnQIx48fB/AslPXo0UPiqoiI6h6VLv4/duwYPD09YWZmhtdffx2ZmZkYOHAgGjVqBFtbW6Vn4MlkMpw/f77aCiaimiWEwN9//43IyEgAwLBhw9C9e3eJqyIiqptUCmYDBgzAqVOn0LVrV1hZWbETWaJ6QgiBv/76CydPngQAvPTSS+jWrZvEVRER1V0qBbOSj9Ms7rOIiOq20qFs+PDh6Nq1q8RVERHVbRp9JBMR1Q1CCBw8eBCnTp0CwFBGRFRTVA5mJa8jI6K6SwiBAwcO4J9//gEAjBgxAl26dJG4KiKi+kHlYDZgwADo6Dz/Jk6ZTIa0tLQXKoqIpCGEwP79+/Hvv/8CAEaOHInOnTtLXBURUf2hcjDr378/GjduXJ21EJGEhBDYt28fTp8+DQAYNWoUvLy8JK6KiKh+UTmYffzxx7zGhKiOKh3KRo8eDU9PT4mrIiKqf3jxP1E9J4TA3r17ERUVBYChjIhISgxmRPWYEAIRERE4c+YMAGDMmDHw8PCQuCoiovqLwYyonhJCYM+ePYiOjgYAjB07Fp06dZK2KCKiek6lYCaXy6u7DiKqQQxlRETaiS1mRPWMEAJ//vknzp49CwAYN24cOnbsKHFVREQEMJgR1StCCOzevRsxMTGQyWQYN24cOnToIHVZRET0/zGYEdUTQgjs2rUL586dg0wmw/jx49G+fXupyyIiohIYzIjqAblcjt27dzOUERFpOQYzojpOLpdj165dOH/+PGQyGSZMmIB27dpJXRYREZWDwYyoDisdyiZOnIi2bdtKXRYREVWAwYyojpLL5di5cycuXLjAUEZEVEswmBHVQXK5HDt27MDFixeho6ODiRMnwt3dXeqyiIjoORjMiOqY0qFs0qRJcHNzk7osIiJSgY7UBRCR5sjlcmzfvp2hjNSWlpYGExMTyGQyBAYGljuNTCZD//79K1xG//79IZPJyh1369YtvPnmm3Bzc4OZmRmMjIzQsmVLvPzyy4iMjNTAFvxPdHQ0XnrpJVhYWKBBgwbo378/jh07ptYyNm/ejJ49e8LU1BQNGjRAnz59EBER8dz5srOz0bx5c8hkMsyZM6fM+NOnT2Pu3Lno1asXTE1NK/28qX5iMCOqI+RyObZt24ZLly5BR0cHkydPZigjlW3YsAG5ublo0aIF1qxZo9Flr1+/Hm3btsW6devQu3dvfPnll/jxxx8xZcoUnDp1Cr1798bJkyc1sq6oqCj06dMHV69exUcffYTPP/8cKSkpGDRoEP766y+VlvHFF19gypQpyM3NxfLly7Fs2TJkZWVh1KhRCA0NrXTejz/+GI8fP65wfEREBH766SekpqbyMWhUPlEPpaWlCQAiLS1N6lI0JjMzUwAQAERmZqbU5VANKywsFJs2bRJLly4Vy5cvF1evXpW6JKplvLy8RL9+/cTq1asFgHKPIQCiX79+FS6jX79+ovTPyuHDh4Wurq5wd3cX9+7dKzNPUVGR+PXXX8U///zzwtsghBDdu3cXpqam4u7du4phqampwt7eXri6ugq5XF7p/I8ePRIGBgaiXbt2Ij8/XzE8Pz9ftGvXTlhaWlb423H27Fmhq6srvv76awFAzJ49u8w0iYmJiu/ozZs3CwBi3bp1VdhSqm1UzR5sMSOq5YqKirBt2zbExsZCR0cHU6ZMQevWraUui2qRCxcuIDo6GjNmzMC0adNgaGiItWvXamTZ7777LuRyOcLDw+Hg4FBmvI6ODl577TV069bthdd1+/Zt/PPPP5g8eTKaNWumGG5hYYFXXnkFN27cwL///lvpMk6ePIn8/HxMnz4d+vr6iuH6+vrw8fHBkydPsHPnzjLzFRUV4dVXX8WwYcMwceLECpdvY2MDU1PTKmwd1RcMZkS1WFFREbZu3YrY2Fjo6urC29uboYzU9scff8DU1BSTJk1Cw4YNMWbMGAQHB6OwsPCFlnv37l2cOXMGvXr1UqtT46dPnyI5OVmlV15enmK+06dPAwB69uxZZpnFw4qnqUhubi4AwMTEpMy44mHlhbvvvvsOsbGx+PHHH1XcSqLyMZgR1VJFRUXYsmULrly5oghlrVq1krosqmXy8vIQGhqKiRMnwszMDAAwY8YMJCYmqnSxe2UuXLgAAPDw8FBrPg8PDzRu3FilV1hYmGK+Bw8eAEC5LXPFw+7fv1/puou7lTl06FCZcYcPHwYAxMfHKw2/e/culixZgo8++gguLi5qbClRWewug6gWKg5lV69eVYQyV1dXqcuiWmj79u148uQJZsyYoRg2bNgw2NraYs2aNRgzZkyVl52eng4AMDc3V2u+0NBQ5OTkqDRtyU6Ts7OzAQCGhoZlpjMyMlKapiIdOnTAoEGDsHPnTrz33nuYOXMmACAwMFARVEsv4//+7//g5OSEd955R6WaiSrDYEZUyxQVFWHz5s24du0adHV1MXXqVLRs2VLqsqiWWrNmDRo3bgwHBwfcvHlTMXzIkCHYsGEDEhMT0bRp0yotuziQFQc0VfXq1atK6ys+1Vjy9Gax4qBX3inK0sLDw/Hqq6/iq6++wldffQUAcHR0xI8//ojZs2crBc0NGzZg7969OHr0qNI1aURVxWBGVIsUFhZi8+bNuH79OkMZvbC4uDj8/fffEEJUeBo8KCgI77//PoBnrU6VtWRlZ2fD2NhY8b59+/YAgJiYGLXqevz4MYqKilSa1sLCQrFOe3t7AOWfrqzsNGdpVlZW2LZtGx49eoTr16/DzMwMHTp0wP79+wEAbdq0AQDk5+fjrbfewqhRo9CsWTPExcUprT8jIwNxcXFo1KgRLCwsVNoeIgYzolqiZCjT09PD1KlT0aJFC6nLolps3bp1EELg119/haWlZZnxy5cvx9q1axXBzMXFBdevX0dRURF0dXWVpi0sLMT169eVrrFydnaGl5cXIiMjERsbq/Jjwbp06YK7d++qvA3Fp2G7dOkC4Nmdla+++qrSdMX9pBVPowobGxvY2Ngo3hefyhwxYgSAZ0E0KSkJf/75J/78888y82/YsAEbNmzAihUrsHDhQpXXS/UbgxlRLVBYWIhNmzbhxo0b0NPTw7Rp09C8eXOpy6JaTC6XIzAwEO7u7njttdfKnebWrVtYuHAhTpw4gd69e2Ps2LFYuXIl1qxZU2aeNWvWIC0tDa+//rrS8C+//BJDhgyBt7c39u/fDzs7uzJ1/P777+jUqZOiy4yqXmPWokULdO3aFZs3b8by5cvh6OgI4Nmp1DVr1qBFixbo3r27Yvq0tDQkJCTA2toa1tbWla7nzJkz+OOPP9CvXz/07t0bAGBqaort27eXmTYpKQmzZ8/GsGHDMGfOHKUaiZ6HwYxIyzGUUXU4ePAg4uPj8fHHH1c4zcSJE7Fw4UKsWbMGvXv3xsKFC7Fjxw7Mnj0bhw4dQo8ePQAAp06dQnh4ONzc3BSta8UGDhyINWvWYPbs2WjdujWmTZsGDw8PGBgY4NatW9i+fTuuXr2q1PN/Va8xA4BVq1ahf//+6NOnD+bOnQsDAwP8+uuvSEhIQEREhNIjo7Zv346ZM2diyZIlWLp0qWL4Rx99hBs3bqBr166wsLDA2bNnsXbtWtjb22P9+vWK6fT19TFu3LgyNRSf0nR2di4z/u7du4plXL58GQCwe/duxenPMWPGoEOHDlXefqoDaqS7Wy3Dnv+ptigoKBAhISFi6dKl4tNPPxW3b9+WuiSqIyZPniwAiAsXLlQ6XYcOHYSpqalIT08XQjzrRX/hwoWiTZs2wsjISBgZGYk2bdqIhQsXitTU1AqXc/36dfGf//xHtG7dWpiYmAhDQ0PRokUL8fLLL2us1/9ip0+fFkOGDBENGjQQJiYmom/fvuLw4cNlplu3bp0AIJYsWaI0fOvWraJ79+6iUaNGwtDQULi6uor33ntPPH36VKX137lzp8Ke/w8fPqz4ri7vxacA1F2qZg+ZEEJIEQillJ6eDgsLC6Slpal9G7e2ysrKUvRBlJmZyZ6l64DCwkJs3LgRt27dUvQ67uzsLHVZRERUBapmD57KJNJCBQUFCA8PZygjIqpnGMyItExBQQE2btyI27dvQ19fH9OnT4eTk5PUZRERUQ3gI5mItAhDGRFR/cYWMyItUVBQgLCwMNy5cwcGBgaYPn06mjVrJnVZRERUgxjMiLRAfn4+wsLCEBcXx1BGRFSPMZgRSax0KPP19VV0jElERPULgxmRhPLz87FhwwbcvXuXoYyIiBjMiKSSn5+P0NBQxMfHw9DQEL6+vio9YJmIiOouBjMiCeTl5WHDhg2KUObn5wd7e3upyyIiIokxmBHVsLy8PISGhuLevXsMZUREpITBjKgGlQxlRkZG8PPzg52dndRlERGRlmAwI6oheXl5CAkJwf379xnKiIioXAxmRDUgNzcXoaGhilDm7+8PW1tbqcsiIiItw2BGVM1yc3MREhKCBw8ewNjYGH5+fgxlRERULgYzompUOpT5+/ujadOmUpdFRERaisGMqJrk5OQgJCQEDx8+ZCgjIiKVMJgRVYOcnBysX78eCQkJMDExgb+/P2xsbKQui4iItJyO1AUQ1TUMZUREVFVsMSPSoJycHAQHByMxMREmJiYICAhAkyZNpC6LiIhqCQYzIg3Jzs7G+vXrkZiYCFNTU/j7+zOUERGRWhjMiDQgOzsbwcHBePToEUxNTREQEIDGjRtLXRYREdUyvMaM6AUxlBERkaawxYzoBWRlZSE4OBhJSUkwMzNDQEAArK2tpS6LiIhqKbaYEVURQxkREWkaW8yIqiArKwtBQUF4/PgxQxkREWkMgxmRmjIzMxEcHIzHjx+jQYMGCAgIgJWVldRlERFRHcBgRqSGzMxMBAUFITk5maGMiIg0jsGMSEUZGRkIDg5GcnIyzM3NERAQAEtLS6nLIiKiOoTBjEgFGRkZCAoKQkpKCkMZERFVGwYzoucoGcosLCwQEBCARo0aSV0WERHVQQxmRJVIT09HUFAQnjx5wlBGRETVjv2YEVWAoYyIiGoaW8yIylEylDVs2BABAQFo2LCh1GUREVEdx2BGVEpaWhqCgoLw9OlThjIiIqpRDGZEJZQOZTNmzICFhYXUZRERUT3BYEb0/6WmpiIoKAipqalo1KgRAgICGMqIiKhG8eJ/IjCUERGRdmCLGdV7qampCAwMRFpaGiwtLREQEABzc3OpyyIionqIwYzqtadPnyIoKIihjIiItAKDGdVbJUOZlZUV/P39GcqIiEhSDGZULz158gRBQUFIT0+HlZUVAgIC0KBBA6nLIiKieo7BjOqdkqHM2toa/v7+DGVERKQVGMyoXnny5AkCAwORkZEBa2trBAQEwMzMTOqyiIiIAGhJdxmrV6+Gi4sLjIyM4OXlhePHj1c47bZt2zBkyBA0btwY5ubm6NGjB/bv31+D1VJtlZKSoghljRs3ZigjIiKtI3kwCw8Px/z587F48WLExMSgT58+GD58OOLj48ud/tixYxgyZAgiIiIQHR2NAQMGYPTo0YiJianhyqk2SUlJQVBQkCKU+fv7M5QREZHWkQkhhJQFdOvWDZ6envj5558Vw9zc3DBu3DisWLFCpWW0bdsW3t7e+Pjjj1WaPj09HRYWFkhLS6szd+FlZWUpgkZmZiZMTU0lrkh7JCcnIygoCJmZmYqWMn4+RERUk1TNHpK2mOXn5yM6OhpDhw5VGj506FCcPHlSpWXI5XJkZGTA0tKywmny8vKQnp6u9KL6oWQoa9KkCUMZERFpNUmDWXJyMoqKimBjY6M03MbGBomJiSot47///S+ysrIwZcqUCqdZsWIFLCwsFC9HR8cXqptqh8ePHyuFMn9/f4YyIiLSapJfYwYAMplM6b0Qosyw8oSFhWHp0qUIDw9HkyZNKpzugw8+QFpamuJ17969F66ZtFvJUGZjY8OWMiIiqhUk7S7D2toaurq6ZVrHkpKSyrSilRYeHo5Zs2Zh8+bNGDx4cKXTGhoawtDQ8IXrpdohKSkJwcHByMrKQtOmTeHn5wcTExOpyyIiInouSVvMDAwM4OXlhYMHDyoNP3jwIHr27FnhfGFhYZgxYwY2bNiAkSNHVneZVIskJSUhKCiIoYyIiGolyTuYXbBgAfz8/NC5c2f06NEDv/32G+Lj4zFnzhwAz05DPnjwAMHBwQCehTJ/f398//336N69u6K1zdjYGBYWFpJtB0nv0aNHCA4ORnZ2Npo2bQp/f38YGxtLXRYREZHKJA9m3t7eSElJwfLly5GQkIB27dohIiICTk5OAICEhASlPs1+/fVXFBYW4j//+Q/+85//KIYHBAQgMDCwpssnLVEylNna2sLPz4+hjIiIah3J+zGTAvsxq1sSExMRHByMnJwc2NnZwdfXl6GMiIi0iqrZQ/IWM6IXUTqU+fn5wcjISOqyiIiIqoTBjGqthIQErF+/Hjk5ObC3t4evry9DGRER1WoMZlQrJSQkIDg4GLm5uQxlRERUZzCYUa3z8OFDrF+/Hrm5uXBwcMD06dMZyoiIqE5gMKNapXQo8/X1ZefBRERUZzCYUa3x4MEDhISEIDc3F46Ojpg+fTpDGRER1SkMZlQrPHjwAOvXr0deXh5DGRER1VkMZqT17t+/j5CQEOTl5aFZs2bw8fFhKCMiojqJwYy0WslQ5uTkBB8fHxgYGEhdFhERUbVgMCOtde/ePYSEhCA/P5+hjIiI6gUGM9JKJUOZs7Mzpk2bxlBGRER1HoMZaZ34+HiEhoYqQpmPjw/09fWlLouIiKjaMZiRVomPj0dISAgKCgrg4uKCadOmMZQREVG9wWBGWuPu3bsIDQ1FQUEBmjdvjqlTpzKUERFRvcJgRlohLi4OGzZsYCgjIqJ6jcGMJFcylLVo0QLe3t4MZUREVC8xmJGk7ty5g7CwMBQUFKBly5bw9vaGnh4PSyIiqp/4C0iSuXPnDjZs2IDCwkKGMiIiIjCYkURu376NsLAwFBYWwtXVFVOmTGEoIyKiek9H6gKo/mEoIyIiKh9/DalG3bp1Cxs3bkRhYSFatWqFyZMnM5QRERH9f/xFpBpz8+ZNbNy4EUVFRWjdujUmTZrEUEZERFQCfxWpRpQOZZMnT4aurq7UZREREWkVBjOqdjdu3EB4eDiKiorQpk0bTJo0iaGMiIioHAxmVK2uX7+OTZs2oaioCG5ubpg4cSJDGRERUQV4VyZVG4YyIiIi9bDFjKrFtWvXsGnTJsjlcri7u2PChAkMZURERM/BYEYad/XqVWzevBlyuRxt27bF+PHjGcqIiIhUwGBGGlUylLVr1w7jx4+Hjg7PmBMREamCwYw05sqVK9iyZQtDGRERURUxmJFGxMbGYuvWrZDL5Wjfvj3GjRvHUEZERKQmBjN6YbGxsdiyZQuEEOjQoQPGjh3LUEZERFQFDGb0Qi5fvoytW7cylBEREWkAgxlV2aVLl7Bt2zYIIdCxY0eMGTOGoYyIiOgFMJhRlZQMZZ06dcLo0aMZyoiIiF4Qgxmp7eLFi9i+fbsilI0ZMwYymUzqsoiIiGo9BjNSy4ULF7Bjxw4IIeDh4YHRo0czlBEREWkIzz2RyhjKiIiIqhdbzEgl58+fx44dOwAAnp6eGDVqFEMZERGRhjGY0XOdO3cOO3fuBAB4eXlh5MiRDGVERETVgMGMKlUylHXu3BkjRoxgKCMiIqomDGZUoZiYGOzatQsAQxkREVFNYDCjcp09exa7d+8GAHTp0gXDhw9nKCMiIqpmDGZURnR0NP78808AQNeuXfHSSy8xlBEREdUABjNSUjKUdevWDcOGDWMoIyIiqiEMZqRw5swZ7NmzBwBDGRERkRQYzAgAEBUVhYiICABA9+7dMXToUIYyIiKiGsZgRjh9+jT27t0LAOjRoweGDBnCUEZERCQBBrN6rmQo69mzJwYPHsxQRkREJBEGs3rs33//xb59+wAAvXr1wqBBgxjKiIiIJMRgVk/9888/2L9/PwCgd+/eGDhwIEMZERGRxBjM6qFTp07hwIEDABjKiIiItAmDWT1TMpT16dMHAwYMYCgjIiLSEgxm9cjJkydx8OBBAEDfvn3Rv39/hjIiIiItwmBWT0RGRuKvv/4CAPTr1w/9+/eXtiAiIiIqg8GsHjhx4gT+/vtvAAxlRERE2ozBrI47fvw4Dh06BADo378/+vXrJ3FFREREVBEGszrs2LFjOHz4MABgwIAB6Nu3r8QVERERUWUYzOqokqFs4MCB6NOnj8QVERER0fMwmNVBx48fx7///guAoYyIiKg20ZG6ANK848ePAwAGDRrEUEZERFSLsMWsjhBCKL0fPHgwevXqJVE1REREVBVsMasDhBA4duyY4v3AgQMZyoiIiGohBrNaTgiBw4cPIzIyUjGse/fuElZEREREVcVTmbWYEAKHDh3CiRMnpC6FiIiINIAtZrWUEAJ///23IpQNHjxY4oqIiIjoRbHFrBYSQuCvv/7CyZMnAQAvvfQS2rVrJ3FVRERE9KLYYlbLlA5lw4cPR7du3SSuioiIiDSBLWa1iBACBw8exKlTpwA8C2Vdu3aVuCoiIiLSFAazWkIIgQMHDuCff/4BAIwYMQJdunSRuCoiIiLSJAazWkAIgf379yseszRy5Eh07txZ4qqIiIhI0xjMtJwQAvv27cPp06cBAKNGjYKXl5fEVREREVF1YDDTYqVD2ejRo+Hp6SlxVURERFRdGMy0lBACe/fuRVRUFACGMiIiovqAwUwLCSEQERGBM2fOAADGjBkDDw8PiasiIiKi6sZgpmWEENizZw+io6MBAGPHjkWnTp2kLYqIiIhqBDuY1SIMZURERPUbW8y0hBACf/75J86ePQsAGDduHDp27ChxVURERFSTGMy0gBACu3fvRkxMDGQyGcaNG4cOHTpIXRYRERHVMAYziQkhsGvXLpw7dw4ymQzjx49H+/btpS6LiIiIJMBgJiG5XI7du3czlBEREREABjPJyOVy7Nq1C+fPn4dMJsOECRPQrl07qcsiIiIiCTGYSaB0KJs4cSLatm0rdVlEREQkMQazGiaXy7Fz505cuHCBoYyIiIiUMJjVILlcjh07duDixYvQ0dHBxIkT4e7uLnVZREREpCUYzGpI6VA2adIkuLm5SV0WERERaREGsxogl8uxfft2XLp0iaGMiIiIKqQVj2RavXo1XFxcYGRkBC8vLxw/frzS6Y8ePQovLy8YGRmhefPm+OWXX2qoUvXJ5XJs27ZNEcomT57MUEZERETlkjyYhYeHY/78+Vi8eDFiYmLQp08fDB8+HPHx8eVOf+fOHYwYMQJ9+vRBTEwMFi1ahLlz52Lr1q01XHnl7t+/j7/++gu//fYbLl++DB0dHUyZMgVt2rSp9nU/ePCg2tdBREREmicTQggpC+jWrRs8PT3x888/K4a5ublh3LhxWLFiRZnp33//fezatQtXrlxRDJszZw7Onz+PU6dOqbTO9PR0WFhYIC0tDebm5i++EaX88ccfmD17NuRyOWQyGUaMGIFPPvkErVq10vi6iv32229YsGABAEBHRwe//fYbZs2aVW3rIyIiItWpmj0kDWb5+fkwMTHB5s2bMX78eMXwefPm4dy5czh69GiZefr27QsPDw98//33imHbt2/HlClTkJ2dDX19/TLz5OXlIS8vT/E+PT0djo6O1RLM7t+/DycnJ8jlco0uV126urqIi4uDg4ODpHUQERGR6sFM0lOZycnJKCoqgo2NjdJwGxsbJCYmljtPYmJiudMXFhYiOTm53HlWrFgBCwsLxcvR0VEzG1COGzduSB7KAKCoqAg3b96UugwiIiJSg1bclSmTyZTeCyHKDHve9OUNL/bBBx8oTvMB/2sxqw6urq7Q0dFRCme6urqIjY2Fvb19tazzwYMHcHNzK7POli1bVsv6iIiIqHpIGsysra2hq6tbpnUsKSmpTKtYsaZNm5Y7vZ6eHqysrMqdx9DQEIaGhpop+jkcHBzw22+/Yfbs2SgqKoKuri5+/fXXar2+rFWrVuWuk6cxiYiIahdJg5mBgQG8vLxw8OBBpWvMDh48iLFjx5Y7T48ePbB7926lYQcOHEDnzp3Lvb5MCrNmzcKwYcNw8+ZNtGzZskYCkhTrJCIiIs2S/FTmggUL4Ofnh86dO6NHjx747bffEB8fjzlz5gB4dhrywYMHCA4OBvDsDswff/wRCxYswKuvvopTp05hzZo1CAsLk3IzynBwcKjxcCTFOomIiEhzJA9m3t7eSElJwfLly5GQkIB27dohIiICTk5OAICEhASlPs1cXFwQERGBt956Cz/99BPs7OywatUqTJw4UapNICIiItIIyfsxk0J192NGREREVFKt6C6DiIiIiP6HwYyIiIhISzCYEREREWkJBjMiIiIiLcFgRkRERKQlGMyIiIiItASDGREREZGWYDAjIiIi0hIMZkRERERagsGMiIiISEswmBERERFpCQYzIiIiIi3BYEZERESkJRjMiIiIiLQEgxkRERGRlmAwIyIiItISDGZEREREWkJP6gKkIIQAAKSnp0tcCREREdUHxZmjOINUpF4Gs4yMDACAo6OjxJUQERFRfZKRkQELC4sKx8vE86JbHSSXy/Hw4UM0aNAAMpmsWtaRnp4OR0dH3Lt3D+bm5tWyDlIN94V24H7QHtwX2oP7QjvUxH4QQiAjIwN2dnbQ0an4SrJ62WKmo6MDBweHGlmXubk5/9i0BPeFduB+0B7cF9qD+0I7VPd+qKylrBgv/iciIiLSEgxmRERERFqCwayaGBoaYsmSJTA0NJS6lHqP+0I7cD9oD+4L7cF9oR20aT/Uy4v/iYiIiLQRW8yIiIiItASDGREREZGWYDAjIiIi0hIMZkRERERagsHsBaxevRouLi4wMjKCl5cXjh8/Xun0R48ehZeXF4yMjNC8eXP88ssvNVRp3afOvti2bRuGDBmCxo0bw9zcHD169MD+/ftrsNq6S92/iWKRkZHQ09NDp06dqrfAekTdfZGXl4fFixfDyckJhoaGaNGiBdauXVtD1dZd6u6H0NBQdOzYESYmJrC1tcXMmTORkpJSQ9XWXceOHcPo0aNhZ2cHmUyGHTt2PHceyX6zBVXJxo0bhb6+vvj9999FbGysmDdvnjA1NRV3794td/rbt28LExMTMW/ePBEbGyt+//13oa+vL7Zs2VLDldc96u6LefPmiS+++EKcPn1aXL9+XXzwwQdCX19fnD17toYrr1vU3Q/FUlNTRfPmzcXQoUNFx44da6bYOq4q+2LMmDGiW7du4uDBg+LOnTvi33//FZGRkTVYdd2j7n44fvy40NHREd9//724ffu2OH78uGjbtq0YN25cDVde90RERIjFixeLrVu3CgBi+/btlU4v5W82g1kVde3aVcyZM0dpWJs2bcTChQvLnf69994Tbdq0URo2e/Zs0b1792qrsb5Qd1+Ux93dXSxbtkzTpdUrVd0P3t7e4sMPPxRLlixhMNMQdffF3r17hYWFhUhJSamJ8uoNdffDV199JZo3b640bNWqVcLBwaHaaqyPVAlmUv5m81RmFeTn5yM6OhpDhw5VGj506FCcPHmy3HlOnTpVZvphw4bhzJkzKCgoqLZa67qq7IvS5HI5MjIyYGlpWR0l1gtV3Q/r1q3DrVu3sGTJkuousd6oyr7YtWsXOnfujC+//BL29vZo1aoV3nnnHeTk5NREyXVSVfZDz549cf/+fUREREAIgUePHmHLli0YOXJkTZRMJUj5m10vH2L+opKTk1FUVAQbGxul4TY2NkhMTCx3nsTExHKnLywsRHJyMmxtbaut3rqsKvuitP/+97/IysrClClTqqPEeqEq++HGjRtYuHAhjh8/Dj09fhVpSlX2xe3bt3HixAkYGRlh+/btSE5Oxuuvv44nT57wOrMqqsp+6NmzJ0JDQ+Ht7Y3c3FwUFhZizJgx+OGHH2qiZCpByt9stpi9AJlMpvReCFFm2POmL284qU/dfVEsLCwMS5cuRXh4OJo0aVJd5dUbqu6HoqIi+Pj4YNmyZWjVqlVNlVevqPM3IZfLIZPJEBoaiq5du2LEiBH45ptvEBgYyFazF6TOfoiNjcXcuXPx8ccfIzo6Gvv27cOdO3cwZ86cmiiVSpHqN5v/TK0Ca2tr6OrqlvlXT1JSUpmEXaxp06blTq+npwcrK6tqq7Wuq8q+KBYeHo5Zs2Zh8+bNGDx4cHWWWeepux8yMjJw5swZxMTE4I033gDwLBwIIaCnp4cDBw5g4MCBNVJ7XVOVvwlbW1vY29vDwsJCMczNzQ1CCNy/fx+urq7VWnNdVJX9sGLFCvTq1QvvvvsuAKBDhw4wNTVFnz598Omnn/LMSg2S8jebLWZVYGBgAC8vLxw8eFBp+MGDB9GzZ89y5+nRo0eZ6Q8cOIDOnTtDX1+/2mqt66qyL4BnLWUzZszAhg0beP2GBqi7H8zNzXHx4kWcO3dO8ZozZw5at26Nc+fOoVu3bjVVep1Tlb+JXr164eHDh8jMzFQMu379OnR0dODg4FCt9dZVVdkP2dnZ0NFR/lnW1dUF8L/WGqoZkv5mV/vtBXVU8W3Qa9asEbGxsWL+/PnC1NRUxMXFCSGEWLhwofDz81NMX3zr7VtvvSViY2PFmjVr2F2Ghqi7LzZs2CD09PTETz/9JBISEhSv1NRUqTahTlB3P5TGuzI1R919kZGRIRwcHMSkSZPE5cuXxdGjR4Wrq6t45ZVXpNqEOkHd/bBu3Tqhp6cnVq9eLW7duiVOnDghOnfuLLp27SrVJtQZGRkZIiYmRsTExAgA4ptvvhExMTGKrku06TebwewF/PTTT8LJyUkYGBgIT09PcfToUcW4gIAA0a9fP6Xpjxw5Ijw8PISBgYFwdnYWP//8cw1XXHepsy/69esnAJR5BQQE1HzhdYy6fxMlMZhplrr74sqVK2Lw4MHC2NhYODg4iAULFojs7OwarrruUXc/rFq1Sri7uwtjY2Nha2srpk+fLu7fv1/DVdc9hw8frvR7X5t+s2VCsH2UiIiISBvwGjMiIiIiLcFgRkRERKQlGMyIiIiItASDGREREZGWYDAjIiIi0hIMZkRERERagsGMiIiISEswmBERERFpCQYzonouMDAQMpms3Nc777yj8nLi4uIgk8kQGBhYfcVWsM7il46ODqysrDBixAicOnWqWtbZv39/9O/fX/E+OzsbS5cuxZEjR8pMW/zZxsXFVUstFTly5IjS56Krq4vGjRtj9OjROHPmTJWXu3r16hrdv0T1kZ7UBRCRdli3bh3atGmjNMzOzk6iatTz5ptvwsfHB0VFRbh8+TKWLVuGAQMG4NSpU/Dw8NDoulavXq30Pjs7G8uWLQMApcAGACNHjsSpU6dga2ur0RpU9fnnn2PAgAEoKChATEwMli1bhn79+uHcuXNwdXVVe3mrV6+GtbU1ZsyYofliiQgAgxkR/X/t2rVD586dpS6jSpo1a4bu3bsDAHr16oWWLVti0KBBWL16NX7//XeNrsvd3V3laRs3bozGjRtrdP3qcHV1VXwuffr0QcOGDREQEICQkBBFmCQi7cJTmURUqZs3b2LmzJlwdXWFiYkJ7O3tMXr0aFy8ePG58z5+/BivvfYaHB0dYWhoiMaNG6NXr17466+/lKb766+/MGjQIJibm8PExAS9evXC33//XeWai8PI3bt3FcPWrl2Ljh07wsjICJaWlhg/fjyuXLmiNN/t27cxdepU2NnZwdDQEDY2Nhg0aBDOnTunmKbkqcy4uDhF8Fq2bJni1GFxi1LpU5nz58+Hqakp0tPTy9Ts7e0NGxsbFBQUKIaFh4ejR48eMDU1hZmZGYYNG4aYmJgqfy7FwfvRo0dKw5ctW4Zu3brB0tIS5ubm8PT0xJo1a1DyUcrOzs64fPkyjh49qthOZ2dnxfj09HS88847cHFxgYGBAezt7TF//nxkZWVVuV6i+ojBjIgAAEVFRSgsLFR6AcDDhw9hZWWFlStXYt++ffjpp5+gp6eHbt264dq1a5Uu08/PDzt27MDHH3+MAwcO4I8//sDgwYORkpKimCYkJARDhw6Fubk5goKCsGnTJlhaWmLYsGFVDmc3b94EAEVoWrFiBWbNmoW2bdti27Zt+P7773HhwgX06NEDN27cUMw3YsQIREdH48svv8TBgwfx888/w8PDA6mpqeWux9bWFvv27QMAzJo1C6dOncKpU6fw0UcflTv9yy+/jOzsbGzatElpeGpqKnbu3AlfX1/o6+sDeHYactq0aXB3d8emTZuwfv16ZGRkoE+fPoiNja3S53Lnzh0AQKtWrZSGx8XFYfbs2di0aRO2bduGCRMm4M0338Qnn3yimGb79u1o3rw5PDw8FNu5fft2AM9O5/br1w9BQUGYO3cu9u7di/fffx+BgYEYM2aMUsAjoucQRFSvrVu3TgAo91VQUFBm+sLCQpGfny9cXV3FW2+9pRh+584dAUCsW7dOMczMzEzMnz+/wnVnZWUJS0tLMXr0aKXhRUVFomPHjqJr166V1l68zi+++EIUFBSI3NxcER0dLbp06SIAiD179oinT58KY2NjMWLECKV54+PjhaGhofDx8RFCCJGcnCwAiO+++67Sdfbr10/069dP8f7x48cCgFiyZEmZaYs/2zt37iiGeXp6ip49eypNt3r1agFAXLx4UVGbnp6eePPNN5Wmy8jIEE2bNhVTpkyptMbDhw8LACI8PFwUFBSI7OxsERkZKVq3bi3c3d3F06dPK5y3qKhIFBQUiOXLlwsrKyshl8sV49q2bau07cVWrFghdHR0RFRUlNLwLVu2CAAiIiKi0nqJ6H94jRkRAQCCg4Ph5uamNExPTw+FhYX48ssvERISgps3byqdait9KrC0rl27IjAwEFZWVhg8eDC8vLwULUIAcPLkSTx58gQBAQGKFrpiL730Er788ktkZWXB1NS00vW8//77eP/99xXvbWxs8Ouvv2LEiBHYu3cvcnJyylyw7ujoiIEDBypa5SwtLdGiRQt89dVXKCoqwoABA9CxY0fo6Gj2xMLMmTPx5ptv4tq1a2jdujWAZzdedOnSBe3atQMA7N+/H4WFhfD391f6XIyMjNCvXz8cPnxYpXV5e3srvbe1tcXJkyfRsGFDpeGHDh3C559/jqioqDKnWZOSkmBjY1Ppev7880+0a9cOnTp1Uqp32LBhkMlkOHLkCIYPH65SzUT1HU9lEhEAwM3NDZ07d1Z6AcCCBQvw0UcfYdy4cdi9ezf+/fdfREVFoWPHjsjJyal0meHh4QgICMAff/yBHj16wNLSEv7+/khMTATwv2udJk2aBH19faXXF198ASEEnjx58tza582bh6ioKERHR+PWrVtISEjAa6+9BgCK06bl3RlpZ2enGC+TyfD3339j2LBh+PLLL+Hp6YnGjRtj7ty5yMjIUPFTfL7p06fD0NBQ0e1EbGwsoqKiMHPmTMU0xZ9Lly5dynwu4eHhSE5OVmldX3zxBaKionD06FEsXrwYjx49wrhx45CXl6eY5vTp0xg6dCgA4Pfff0dkZCSioqKwePFiAHjuPi6u98KFC2VqbdCgAYQQKtdLRLwrk4ieIyQkBP7+/vj888+VhicnJ5dpeSnN2toa3333Hb777jvEx8dj165dWLhwIZKSkrBv3z5YW1sDAH744QfFBfulPa+1BgAcHBwqvKPUysoKAJCQkFBm3MOHDxU1AICTkxPWrFkDALh+/To2bdqEpUuXIj8/H7/88stz61BFo0aNMHbsWAQHB+PTTz/FunXrYGRkhGnTpimmKa5py5YtcHJyqvK6mjdvrvhc+vbtC2NjY3z44Yf44YcfFH3Ubdy4Efr6+vjzzz9hZGSkmHfHjh0qr8fa2hrGxsZYu3ZtheOJSDUMZkRUKZlMBkNDQ6Vhe/bswYMHD9CyZUuVl9OsWTO88cYb+PvvvxEZGQngWdcWDRs2RGxsLN544w2N1l2sR48eMDY2RkhICCZPnqwYfv/+fRw6dAiTJk0qd75WrVrhww8/xNatW3H27NkKl1/82ajSslRs5syZ2LRpEyIiIhASEoLx48crhdxhw4ZBT08Pt27dwsSJE1Ve7vO89957CAwMxMqVKzF79mw0aNAAMpkMenp60NXVVUyXk5OD9evXl5nf0NCw3O0cNWoUPv/8c1hZWcHFxUVj9RLVRwxmRFSpUaNGITAwEG3atEGHDh0QHR2Nr776Cg4ODpXOl5aWhgEDBsDHxwdt2rRBgwYNEBUVhX379mHChAkAADMzM/zwww8ICAjAkydPMGnSJDRp0gSPHz/G+fPn8fjxY/z8888vVH/Dhg3x0UcfYdGiRfD398e0adOQkpKCZcuWwcjICEuWLAEAXLhwAW+88QYmT54MV1dXGBgY4NChQ7hw4QIWLlxY4fIbNGgAJycn7Ny5E4MGDYKlpSWsra2VupIobejQoXBwcMDrr7+OxMREpdOYwLOuKZYvX47Fixfj9u3beOmll9CoUSM8evQIp0+fhqmpaZX6IdPX18fnn3+OKVOm4Pvvv8eHH36IkSNH4ptvvoGPjw9ee+01pKSk4Ouvvy4TxgGgffv22LhxI8LDw9G8eXMYGRmhffv2mD9/PrZu3Yq+ffvirbfeQocOHSCXyxEfH48DBw7g7bffRrdu3dSul6hekvruAyKSVvGdg6XvqCv29OlTMWvWLNGkSRNhYmIievfuLY4fP17m7sTSd2Xm5uaKOXPmiA4dOghzc3NhbGwsWrduLZYsWSKysrKU1nH06FExcuRIYWlpKfT19YW9vb0YOXKk2Lx5c6W1F6/zq6++eu52/vHHH6JDhw7CwMBAWFhYiLFjx4rLly8rxj969EjMmDFDtGnTRpiamgozMzPRoUMH8e2334rCwkLFdKW3Wwgh/vrrL+Hh4SEMDQ0FABEQECCEKP+uzGKLFi0SAISjo6MoKioqt+YdO3aIAQMGCHNzc2FoaCicnJzEpEmTxF9//VXpthbflVnR59etWzfRqFEjkZqaKoQQYu3ataJ169bC0NBQNG/eXKxYsUKsWbOmTO1xcXFi6NChokGDBgKAcHJyUozLzMwUH374oWjdurXiM27fvr146623RGJiYqX1EtH/yIRgBzNERERE2oB3ZRIRERFpCQYzIiIiIi3BYEZERESkJRjMiIiIiLQEgxkRERGRlmAwIyIiItISDGZEREREWoLBjIiIiEhLMJgRERERaQkGMyIiIiItwWBGREREpCX+H5jpWsZq4nXkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 700x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1, figsize=(7,7))\n",
    "baseline_probs = [0 for _ in range(len(y_test))]\n",
    "\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = grid_clf.predict_proba(X_test[selected_cols])\n",
    "probs = probs[:, 1]\n",
    "\n",
    "# calculate scores\n",
    "baseline_auc = roc_auc_score(y_test, baseline_probs)\n",
    "auc = roc_auc_score(y_test, probs)\n",
    "auc = ('AUC=%.3f' % (auc))\n",
    "\n",
    "# calculate roc curves\n",
    "baseline_fpr, baseline_tpr, _ = roc_curve(y_test, baseline_probs)\n",
    "fpr, tpr, _ = roc_curve(y_test, probs)\n",
    "\n",
    "# plot the roc curve for the model\n",
    "ax.plot(baseline_fpr, baseline_tpr, color='gray')\n",
    "ax.plot(fpr, tpr, marker='.', color='black')\n",
    "\n",
    "# axis labels\n",
    "ax.set_xlabel('False Positive Rate',fontsize=12)\n",
    "ax.set_ylabel('True Positive Rate',fontsize=12)\n",
    "ax.set_title('Receiver Operating Characteristic', fontsize=16)\n",
    "plt.text(.6, .3, auc, fontsize=13)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aebfafd",
   "metadata": {},
   "source": [
    "## Export Models and Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "73c49df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2660f161",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['base.pkl']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_1 = base_model_1(X.drop(['a', 'b', 'name_a', 'name_b'], 1), y, X_test=None, export=True)\n",
    "joblib.dump(base_1, filename='base.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16a56040",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_2(X[['name_a', 'name_b']], y, X_test=None, export=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "de9f1498",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['meta.pkl']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(grid_clf.best_estimator_, filename='meta.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
